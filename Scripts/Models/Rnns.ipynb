{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full,y_train_full), (X_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Erklärung der Schichten***\n",
    "1. Flatten: nimmt die Eingabe und macht daraus ein 1D Array\n",
    "2. Dense: 300 Neuronen, mit ReLU Aktivierungsfunktion\n",
    "    Die erste Sicht hat bspweise \n",
    "    \n",
    "                                28 x 28 = 784 \n",
    "\n",
    "                                784 x 300 + 300 Bias-Terme = 235.500\n",
    "                                \n",
    "    was sich zu 235.500 Parameter ausfummiert. Jedoch Risiko overfitting.\n",
    "3. Dense: 100 Neuronen, mit ReLU Aktivierungsfunktion\n",
    "4. Dense: 10 Neuronen, mit Softmax Aktivierungsfunktion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste mit den sichten eines Modells erhalten, um eine davon über ihren Index anzusprechen, oder Sie gehen über den Namen vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x283982130>,\n",
       " <keras.layers.core.dense.Dense at 0x2836e9d30>,\n",
       " <keras.layers.core.dense.Dense at 0x2836e99a0>,\n",
       " <keras.layers.core.dense.Dense at 0x2836ea340>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_18'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights() # get_weights() and set_weights() are used to get and set the weights of a layer\n",
    "print(biases)\n",
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Es ist gut das alle biases auf 0 gesetzt sind. Da wir das so möchten um die Symeterie zu erhalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Das Model compilen und trainieren***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sparse_categorical_crossentropy wird verwendet, weil wir spärliche Beschriftungen haben (d.h. für jede Instanz gibt es nur einen Zielklassenindex, in diesem Fall von 0 bis 9), und die Klassen sind exklusiv.\n",
    "- Hätten wir stattdessen eine Zielwahrscheinlichkeit pro Klasse für jede Instanz (wie z.B. One-Hot-Vektoren, z.B. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], um Klasse 3 zu repräsentieren), dann müssten wir stattdessen den categorical_crossentropy loss verwenden.\n",
    "- Wenn wir eine binäre Klassifizierung durchführen (mit einem oder mehreren binären Labels), dann würden wir in der Ausgabeschicht anstelle der Softmax-Aktivierungsfunktion die sigmoide (d.h. logistische) Aktivierungsfunktion verwenden und den binary_crossentropy loss einsetzen.\n",
    "- Wenn wir regressieren würden, dann würden wir keine Aktivierungsfunktion in der Ausgabeschicht verwenden, und wir würden den Verlust mean_squared_error verwenden.\n",
    "- Der Optimierer ist der Algorithmus, der zur Aktualisierung der Gewichte des Modells verwendet wird. Der gebräuchlichste Optimierer ist der Stochastische Gradientenabstieg (SGD), aber es gibt noch viele andere, und einige von ihnen sind viel schneller als SGD. Einige Optimierer sind auch in der Lage, die Lernrate während des Trainings automatisch zu verringern, so dass Sie sie nicht manuell einstellen müssen. Dies ist der Fall beim Adam-Optimierer, der sehr beliebt ist.\n",
    "- Das Argument metrics wird verwendet, um die zu berechnenden Metriken anzugeben. In diesem Fall geht es nur um die Genauigkeit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7075 - accuracy: 0.7667 - val_loss: 0.5064 - val_accuracy: 0.8314\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4869 - accuracy: 0.8311 - val_loss: 0.4324 - val_accuracy: 0.8540\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4411 - accuracy: 0.8457 - val_loss: 0.4232 - val_accuracy: 0.8512\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4151 - accuracy: 0.8543 - val_loss: 0.4028 - val_accuracy: 0.8620\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3952 - accuracy: 0.8609 - val_loss: 0.3906 - val_accuracy: 0.8660\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3791 - accuracy: 0.8674 - val_loss: 0.3795 - val_accuracy: 0.8674\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3647 - accuracy: 0.8720 - val_loss: 0.3733 - val_accuracy: 0.8646\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3530 - accuracy: 0.8744 - val_loss: 0.3554 - val_accuracy: 0.8780\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3441 - accuracy: 0.8783 - val_loss: 0.3461 - val_accuracy: 0.8786\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8818 - val_loss: 0.3404 - val_accuracy: 0.8760\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3257 - accuracy: 0.8835 - val_loss: 0.3314 - val_accuracy: 0.8830\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3165 - accuracy: 0.8875 - val_loss: 0.3529 - val_accuracy: 0.8760\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3101 - accuracy: 0.8887 - val_loss: 0.3256 - val_accuracy: 0.8874\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3030 - accuracy: 0.8926 - val_loss: 0.3227 - val_accuracy: 0.8806\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2968 - accuracy: 0.8927 - val_loss: 0.3272 - val_accuracy: 0.8796\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2914 - accuracy: 0.8947 - val_loss: 0.3276 - val_accuracy: 0.8830\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2853 - accuracy: 0.8968 - val_loss: 0.3194 - val_accuracy: 0.8858\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2795 - accuracy: 0.9007 - val_loss: 0.3177 - val_accuracy: 0.8840\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2743 - accuracy: 0.9015 - val_loss: 0.3112 - val_accuracy: 0.8880\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2691 - accuracy: 0.9028 - val_loss: 0.3176 - val_accuracy: 0.8866\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2656 - accuracy: 0.9033 - val_loss: 0.3043 - val_accuracy: 0.8922\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2600 - accuracy: 0.9070 - val_loss: 0.3061 - val_accuracy: 0.8910\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2564 - accuracy: 0.9077 - val_loss: 0.3309 - val_accuracy: 0.8788\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2504 - accuracy: 0.9103 - val_loss: 0.3156 - val_accuracy: 0.8870\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2470 - accuracy: 0.9109 - val_loss: 0.2988 - val_accuracy: 0.8928\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2431 - accuracy: 0.9126 - val_loss: 0.2989 - val_accuracy: 0.8950\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2385 - accuracy: 0.9142 - val_loss: 0.2919 - val_accuracy: 0.8978\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2343 - accuracy: 0.9153 - val_loss: 0.2977 - val_accuracy: 0.8922\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2305 - accuracy: 0.9177 - val_loss: 0.3103 - val_accuracy: 0.8894\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2281 - accuracy: 0.9180 - val_loss: 0.2881 - val_accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=30, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGyCAYAAACiMq99AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9lUlEQVR4nO3dd3xUVeI28OdOb+m9EyCh14SqCIqAoOgqViyguMraVlkb+lPRVVl3Vxd9FStgA3UV2woKUaRb6CCEFkjvfXq97x8zmWRSIAlJJgnP18985vZ7Zg4jD+fec64giqIIIiIiIqIuIPF3AYiIiIjo/MHwSURERERdhuGTiIiIiLoMwycRERERdRmGTyIiIiLqMgyfRERERNRlGD6JiIiIqMswfBIRERFRl2H4JCIiIqIuw/BJRERERF2mzeFz69atmD17NmJjYyEIAr7++uuz7rNlyxakpaVBpVKhb9++eOutt9pTViIiIiLq4docPo1GI0aMGIHXX3+9VdufPn0as2bNwqRJk7Bv3z488cQTeOCBB7B27do2F5aIiIiIejZBFEWx3TsLAr766iv86U9/anGbxx57DN9++y0yMzO9yxYuXIgDBw7gl19+ae+piYiIiKgHknX2CX755RdMnz7dZ9mMGTOwYsUK2O12yOXyJvtYrVZYrVbvvMvlQmVlJcLCwiAIQmcXmYiIiIjaSBRF6PV6xMbGQiJp+eJ6p4fP4uJiREVF+SyLioqCw+FAeXk5YmJimuyzdOlSPPvss51dNCIiIiLqYHl5eYiPj29xfaeHTwBNWivrrvS31Iq5ePFiLFq0yDtfU1ODxMREnD59GgEBAZ1XUA+73Y6ff/4ZF198cbMts9T5WAf+xzroHlgP/sc68D/Wgf+1pg70ej2Sk5PPmtU6PXxGR0ejuLjYZ1lpaSlkMhnCwsKa3UepVEKpVDZZHhoaisDAwE4pZ0N2ux0ajQZhYWH8Q+4nrAP/Yx10D6wH/2Md+B/rwP9aUwd1y892i2Snj/M5YcIEZGRk+CzbuHEj0tPT+QeIiIiI6DzT5vBpMBiwf/9+7N+/H4B7KKX9+/cjNzcXgPuS+W233ebdfuHChcjJycGiRYuQmZmJlStXYsWKFXj44Yc75hMQERERUY/R5svuu3fvxsUXX+ydr7s3c968eXj//fdRVFTkDaIAkJycjPXr1+Ohhx7CG2+8gdjYWLz22muYM2dOBxSfiIiIiHqSNofPKVOm4ExDg77//vtNlk2ePBl79+5t66mIiIiIqJfhs92JiIiIqMswfBIRERFRl2H4JCIiIqIuw/BJRERERF2G4ZOIiIiIugzDJxERERF1GYZPIiIiIuoyDJ9ERERE1GUYPomIiIioyzB8EhEREVGXYfgkIiIioi7D8ElEREREXYbhk4iIiIi6DMMnEREREXUZhk8iIiIi6jIMn0RERETUZRg+iYiIiKjLMHwSERERUZdh+CQiIiKiLsPwSURERERdhuGTiIiIiLoMwycRERERdRmGTyIiIiLqMjJ/F4CIiIjovOe0AzYDYLcAoguACIhiM9Nwv4uiZ/lZppWBQHh/v32s5jB8EhEREZ2JKLrDodPmedkBl71+2mZs8DJ4XkbA2mC62XXG+nmntXPKnjIduPnzzjl2OzF8EhERUfcjiu5wZzcDFgM01jKg/DgAB+CwAg6L77vd3HSZz7vFd97p8A2TTpsnUNqbWe7ous8tSNwvCJ5pocF84+mW1nn2gwBowruu7K3E8ElERHQ+EkXfljer3h3MRCfgcjZ4dzWab7zc1Whd3bzDHfLsDYKf3QI4zL5h0e6Zd5ibrocIAJADmAYAR/z4fTUmVQJSBSCVAXItoGjwUgY0mNd5Xg3mlboG6xq9yxT+/mSdjuGTiIjIXxoGNe/L2cx0M9uIzgaXfD2Xc+su81r1TS/9NrfME+66OxECnBI5pEotBJkKkCkBmarBS9n8u7zxes+0VOkOeVLPSyKrn5bKG7zLfZdLPPMSqadlkdqD4ZOIiKi9HFbAVAmYKz3vVQ2mKwGTZ95cVb/MaqgPkd0i/AmeljqdO5hJpIAgbfAuaTQvdV/WrXs/07ZyFSBTu48rV9cHwLrl8gYB8gzrHS4B67//HrNmzYJcLvf3F0bniOGTiIi6N5fTfd+dw+q5B8/qO+20e+Zt9du57J5WRU/LYuNLxKLYYL7xNqLPvMRpx/C8Q5B+uRawVHvCZLU7TNqNnfOZBYm7NU4iqw9zdfMSme+8QuO5lBvQ6LJugOdd1+BSsK7BMs+0XNP9W/Hsdn+XgDoQwycREbXM5XIHLlMlYKpwv8yeaXO1J+Q1uCTstDd/idhnvvHLs95pAxx1HT0ahErR6devQAogGQDKW9hAkADqEEAd6n7XhLqnNaGAOrjBtGe9KrDlIOkNmxyGm3ovhk8iovOFywlYajyXgCsavCp9p80Ng2ZV/diC3YVU4fvy3rundN+XJ1O6782ruwTc+BKxIDSab7he0mR7J4ATuSVIGTYGUl1EgyAZ7J5WBjEsdjOiKEK0WOAyGOA0GODyvNzTRog2G2QREZDHREMWHQ1pcDCE7t7624swfBIRdQd14wjaTe5evp53wVyLcP1hCMcFwGVzL7eZPOs929qM9fMN19nqjmV0T5/LOILKwAYtemHulzq4vrNGS614Ulmj9Y23kXvmpY0CpSdI1vUobtg5pItDgstux7H169Fv7CxIeb9hpxHtdrjMZvfLZILYYNqu1yNw925UV1VBMJu9IdKl18Np9Ez7BEwD4Gx9i7mgVEIWHQV5dAzk0VGQRUW7g2lUtHs+JqbbB1TRboe9pAT2/HzYCwpg87yrBgxE2II7/F08HwyfRHR+cdobtPw16ChS1/lDbNABxPukkLplzU2LvtvWncNu9gmR9e9nWNbM5WUZgAsA4GQHfgeKAHeQ1DQIkpqw+svDDZfVBc7zYPiXxlw2GxwlJbAUFEB96hTM+w/AoVZDkMvdL4XC8y6vXyaXQzhPW0FdJhPsxcWwFxbBUVwEe2kpXEajO0Sa3CHSHS5NEE3m+qDpCZhnu68zGi3f+dAiiQQSnQ4SnRZSrc49HaCDIJHCUVYGe3ExnBUVEK1W2HNyYc/JbfFQ3oAaFe0NqnXv0uBg9zkCAtzn0GggSKVtLe0ZiU4nHCUlnmBZAHtBQX3QLMiHo7jEfZtMI86JFQyfREQdxm5pcIm44eXiqgb3Jlb6Tltr/V3qsxMk7nED5WqIcjX0Fid0oZGQKLTuziEKjXe9e1rTYHnjebVnDELPMmWAu1XxPFcXLB3Fxe7AVFwMR1Ex7A2WOSsqvNsnACh4+53WHVwq9Q2njV7S4GCoR4+CJj0dmpEjIdFqO+dDdiB3q1qpO1QWFcFeVAx7UaH7Oysuhr2oCK6amo45mUwGiVrtfQlaDQSVChVGE6KSkyELCIAkIMAd9nQ6SDyhUhrgCZeeZVKdFoJGc9bWSpfNBkdpKRxFRbAXl8BeXARHcYn7z0Sx+8+Es7y8VQG1IYlG4wm7Ab7hty4M6wIaTNctDwBEF+yFhbDn58NWUAB7XdAsKgIcZx7sXlAoII+Lc7/i3e+qAQNa/dV3FYZPIup4dkuDewjL6wOg3dSgQ0mDV7PLrPB90oj75TTZYC62w1Frh1xlgkLnhEztdD/Yo9WERh1BQtyXc4H6p4LUvTdZBt/1zS2T1IdHdxBUN5pu/N5omVTuPa7DbsfP69dj1qxZkPTgS76iy+W+RFpVBUdVFZwNXu75asDpcAc2hdLzrnC3KioUkHjnG65vbp0CglIJuFzu8FBSAntRfYhwFBW5w0SDYHkmglIJWWQkDBYLtEol4HBAtNt9Xk0CgdMJ0emEaLG0eFzTb7+hAgCkUqiGDHEH0fQ0aEaPhjQ4uL1fc7u5LBbYTp+GLS/P/R15Q6U7YDrKynyvCrRAotO5L1fHxEAeFeUOhhoNJBo1BLUaErV7WqLRuINl3by6wTJF01Z2u92Og+vXY0QnDLUkUSigiI+HIj6+xW1aDKgl7n+0OGtrvZf861pwXSaTu0W3tLTjCiuXQx4TA4UnWMrj4n2Cpiw8vEe0vDN8EtGZuZyAsca3g4qxvEFHlfJG6yo6bPgZUQTsBilM5QqYPS9rjQzu553IAWjcG0pEKAIkkIcqoQjXQR4ZDEVMFOTxsVAkJkESGlN/Obmuo4ikYy+JdSXR5XL/xdawI4XeAJfRt1NFc/fDiS4XJEolBLUKEqUKgkoFiUoJQVn/LqiUkKjUnncVBGXdu2cblRoSlRKQyuCsqYazqtoTJCsbBMtqOCsr4ayugsOzvi334HUFQamEPNrd4UQeHQVZ3f1+0dHe5dLgYDgcDqz3/AOgueAjulwQHQ6INps7kNrqgqmtPqA2CKu2/HyY9+yBaddu2AsLYTl4EJaDB1G5ciUAQJma6g6jY9KhTkuDPDKywz6z02CE7VQWrCezvO/WrCzY8/PPGi4FudwdKqOj6wNmdAzksTHu7ywmBtKAgA4ra3fSmoBax2WzwaXX+/4W636ben3979HoWa/3rPP8VuFyQR4bC3l8PORxsVDE1wXMeMgiIjr8cr4/MHwS9XQOq2dg6yr30Dc2Q9NH2rVi3mkwwVZugL3SAlulFbYqO0Ya7Ch/734odA7Pywm5ztG63CaR+943qAmrf3Sc9+khyvppmRIupwBLTgVMJ0tgPlkA87E8OGubBll5TCQU8bGwl1bCVlgI2B2w1Yiw1VhgPG2B+86w+pskpWFhUCQkQJ6Q0OA9HvKERMgiur6lQBRFiCYTnLW1cNbUwFlTC2dtDVze6fp5R00NEvLykfvOu3AZ6/7SMraqFao7kmi1kIaEeF7BkIWEuqeDgyHIZRBtNrhsNneQs9khWq2eaRtEe6N13mnfl8tuB0QR8shInyDp7kAS5RMsO6IDiSCRuFvrmmmxa44WQMj11wMA7IWFMHmCqGn3bthOnYL1+HFYjx9H1Zo1AABFUhLUY9KhSXMHUnlc3FnL7aiqgi0rC9asU7BmnYQt6xSsWVlwFBe3uI8kKAiKpCR38GkYMD0vaWhoj2hV8zeJQgFJWBgQFubvonRbDJ9EfiKKorslSBQhyGTu0GiubhAkm3lZqptuYze18nyA0yqBzSCFXS+DzSBzT3vendbmEqUcJjRt6ZEFyqEI10IRFQJ5bCQUCfFQJPWBPDkV0sh4d9BUBp61V7K9uBjmfftg3r8fpn2/wXLkSJNLmIJcDtXQoVCPGgX1yBFQjxzp0xJUdxO+LS8f9rzcRu95cFZXw1lRAXNFBcz79zcpg6BUQh4fD4lOC0EmhyCTeV+Qy3yXyWWAzLNM3sJymQyi0wFXba07SNbUeIJkbX3YrK09671bDakB2JpbIZU2uFfM3ZGiyX1lAQHee+IkOi0EiQQuiwWixQqX1f0uWi1wWazuoWmsFohmC1zWBvMNt7VYPPtbIDockAYFQRoa2iBMhkAa0mDeu84dMCVK3m/akDw2FkGxsQiaPRsA4Cgvh2nPXph2u8Oo9ehR2HJyYMvJQc0XawEAsuhoz2X6dKhHDIezuro+ZJ7MgvXUqTPeViCNCIeyX38o+/aFon8/KPv2g7J/P0jDwrp1b27qPRg+iVpBFEXYc3Jg/OUXGHf+AntBAUSXy31vV+N3p9N9X5jTATgd7nmXE6LTBbhcEF0i4GrUaiURIZWJkMhckMhFSGQiJPJG0zIRErkIaeNtZHJIFIAkIBASXRBc0MCml8FWC9hrRdiqHbBV2WGvMMNlPfNlT2mQDoqYCMjjoiCLjcbpyiokhcbAWVLhHrYjJxcuoxGOWjsctdUwnaoGcBrAb/XHCA2FIjER8sQEKBKToEhMcM/Hx8NeVBc298G0bz8cRUVNyxARDs3IUe6wOWokVEOGQHKGFiVBKnW31MTGAuPGNlnvrK1137ifmwd7fp7ve1ERRKsVtqysM34vnUYuhzQw0PuSBAdBGhjkng8KhDQoCKJGi30njmPMRRdBEeTbo1ZQKhkWehlZeDgCZ0xH4IzpANx/fs379rnD6K7dMP/xBxzFxaj97jvUfvfdGY8lj42Fol8/KPv1g6JfX3fg7NcX0qCgrvgoRC1i+CRqzOUEbEY4ivLcYfP33TDuOQRHWWUnnlOA0ybAaTvXS1oWz6tlspgYKBISoEhKhDwhEYrERCgSEyBPTIRUp/NuZ7fb8ev69UhrcJ+bKIpwVlXBlpMDe14ebDm5sOW5e3/a8vLc9/hVVsJcWdlsK2MTUilUAwZAPXKkJ2yOgjwutkMDlTQwENLBg6EaPLjJOtFud3eqyM+Hy2yGaHdAdLg7kIjejiWe6brl3vlmltntEB0OCBIJJJ7wKA0MgjQoEJJAz3xQkDdstqYnrt1uh3H9emjGjeMzrc9D0sBA6CZPhm7yZADuTizmgwe9l+kthw9DFhYGRX93S6ayfz8o+vaDsm9yj+hFT+cnhk/qfewWwFgKGMoAQ4l72lgGWPXuwbhtRvclbu+0e95lNMKUZ4GxUICxWAlrje9f9IJEhDrcBm2UFcoQOwQBEASxvpOzRGzQAVoEFBoIqiBAEwRBEwJogiFo3Y/eEzQhgDYMgi4M0ITAJarhcsnhstjhMpngNBrd9/cZjZ6b1Ru/DA22MXmXw+kEZDL3TeqJSb4hM8nd+ngulz0FQYAsNBSy0FBg1Kgm650GA+y5ubDl5sKWmwdbbg7suXmw5ebCUVwMSVAQ1CNHQDNqFNQjR0E9bKhf/4IU5HL3d5SQ4LcyELWFRKOBdvx4aMeP93dRiNqN4ZN6hoaB0ljqDpXeac+rbr21dWPNiS7AXCmHsVgJY4kS5nIFIPr21FSGOqGNl0KbpIQmKRASXSCg0LrHSvQOzB3S/KDcclWrP15H9F2se5xc3b2I/iDV6VpuZbTZ3PdFssMCEdF5jeGTzpnodLo7UlRVwWUy+/RM9emBarNBtDbqmWq3uTswGKsgGqogGqohmvRwmQ0YaqpF6XtPQiJYIJVY3Pc5eu6DlPpM190D6fI+thlSBaCNBHSelzYcojIItkoHjCcqYTxaBNPRfLjMvt045DFR0I4fC+3EC6GZeAFkPai3oiAIENRqfxejRc2N3UdEROcfhk/yUTcEjHtcvsr6QaArGw4IXdlgXL8qOGtqmn2kV0dwR8O6MR1bQSaDVKeFxOfJEQEQ5BKY9293D5TcgDQoCJoJE6CdMAHaiRN4+ZWIiKiTMXyeh5y1tbD88QfMBw/CeuKkZ2Boz4DQVVXuy6PtINFqIFHKPK2PTgiCAwLskIhWCBL3E2gEqQhB4nlJAYlEdC+TSSFogyDoQiAEhAG6MOSWGxAX1x9wyeGyuuC0OOrHOawboFdv8B330OGAs7oGzurmL70LSiU0aWnQTpwAzYQJUA0axMvAREREXYjhs5cT7XZYjh2H5dBBmA8chPngQdhOnTrrfoJS6Rm7Lxiy4BD3sC9aGaRKF2QyK6SCHlKxClJHKWT2QkhRc+bHGwpSICgOCE5yv0Iaveui3I8k9LDb7chZvx5DWvkoNfcTX8zep0i49Ho4GzxFwmU0QZmaCvWokRxnkIiIyI8YPnsRURRhLyiA5WB90LQcOQLRam2yrTw+Hurhw6EaMhiyiAj38C9KF2QSPaSuKgimAgg1uUBVNlB1BNB7xmN0el4N1WVGXRQQ0gcITmwaMAPj3E+x6SSCRAKpTgupTgtERXXaeYiIiOjcMHx2MtPefTBs3gxBLodEp4M0wPOkEW3d/Yg6SDwDRks0mjZdAnbW1sJ88FB9q+ahQ80+1UISGAj1sGFQjxgO1aAUqGOUkNnygdKjQPn3QE42UJ0LOJuGVB8KnTtchvTxhMo+7mBZFzjl3bezCxEREXUPDJ+dQHQ4oP/xR1Sueh/mAwfatK9Eq235MXm6AEi0WtgLCtyXz0+fbnoAudw9aPfQwVAnh0MVKYFCUgyh/BhQ+i6wI7flkwtSIDihmWDZx/2uCT3r4xKJiIiIzoThswM5DUbUrP0ClR9+BHtBAQD3INYBM2ZAotO6Bwv3dJZx1nWc0evhNBi8z3n2DhZeUtKqc8rj46Ee0AfqhECoI5xQKkogqToGVP0InHa5n3zYmC4aiBwIRA4GIgYAIcnucBkYB0j5R4KIiIg6D5NGB7AXFaHyo49R/d//wmUwAACkwcEImXsTQubOhSw8/Iz7i6LoHgezLpgaDHDpDd7OM06DwR1cayrhLDoJmcQIdagZKmUBZKa9gOt39xMV8xodWB0CRA7xBM1BQMQg97smtHO+CCIiIqKzYPg8B+bDh1G56n3U/vCDt+VS0acPQufPR9BVV0LSygG/BUGAoFS6e2E3HtS8Igs4kQGc2AiUbgeCPPdl2j0vAFAEuENlXWtmXdDURfIyOREREXUrDJ9tJLpcMGzegspVq2Datcu7XDN2LELnz4duyuRzGzfSbgFydtQHzsos3/VBiUDSRCBqsOey+UAgKJ4hk4iIiHoEhs9WcpnNqPnmG1S+/wFs2dnuhTIZAmfOROi8eVAPHdL+g1fnesJmBnB6C2A31a+TyNxhM2W6+xWeyqBJREREPRbD51k4yspQuWYNqj/5FM7qagCAJCAAwddfh9BbboE8JqbtB3Xagdxf3S2bJzKAskzf9QExQMo0d9hMngyoAs/9gxARERF1AwyfLVAUF6Pk6Wdg+O47iHb3zZXyuDiEzrsNQdfMcQ9m3hb64vpL6ac2A9ba+nWCBEgYVx84o4aydZOIiIh6JYbPRuwFBSh8+mn02bETes8y9YgRCL39dgRcOhWCrI1fWf5uYN3fgKL9vss14Z6wOQ3oezF7oBMREdF5geGzEWlwMCwHD0EUBOgunYrwO+6AZtSo9h2sJh9YcwNgKgcgAHGjPfduTgNiRvk8y5yIiIjofMDw2YhEq0XU0hexMzcX0269FXJ5O59H7rAC/73NHTyjhwG3fOke+oiIiIjoPMamt2ZoJ0+GvfF4m231/WNAwR5AFQzc8DGDJxEREREYPjvHvo+BPasACMCcFe5HVxIRERERw2eHK9wPfLfIPX3xE0DKpX4tDhEREVF3wvDZkUyVwGe3Ak4rkHoZMOlhf5eIiIiIqFth+OwoLiew9k6gJhcISQaufpu92YmIiIgaYTrqKJuXAlk/ATK1u4OROtjfJSIiIiLqdtoVPpcvX47k5GSoVCqkpaVh27ZtZ9x+9erVGDFiBDQaDWJiYnD77bejoqKiXQXulo6uB7b+yz195WtA9FD/loeIiIiom2pz+Pzss8/w4IMP4sknn8S+ffswadIkzJw5E7m5uc1uv337dtx2221YsGABDh8+jM8//xy7du3CnXfeec6F7xYqsoCv7nZPj70bGH69f8tDRERE1I21OXy+8sorWLBgAe68804MGjQIy5YtQ0JCAt58881mt//111/Rp08fPPDAA0hOTsaFF16Iu+++G7t37z7nwvudzQh8dov7Oe0J44Hpz/u7RERERETdWpuecGSz2bBnzx48/vjjPsunT5+OnTt3NrvPxIkT8eSTT2L9+vWYOXMmSktL8cUXX+Dyyy9v8TxWqxVWq9U7X1tbCwCw2+2w2+1tKXK71J3jjOcSRUi/uQ+S0iMQtZFwXP0eIApAF5TvfNCqOqBOxTroHlgP/sc68D/Wgf+1pg5aWz+CKIpia09cWFiIuLg47NixAxMnTvQuf/HFF/HBBx/g2LFjze73xRdf4Pbbb4fFYoHD4cCVV16JL774osVHVy5ZsgTPPvtsk+Vr1qyBRqNpbXE7Vd/SDRhWsBouSLEj5XFU6gb4u0hEREREfmMymTB37lzU1NQgMDCwxe3a9Wx3QRB85kVRbLKszpEjR/DAAw/g6aefxowZM1BUVIRHHnkECxcuxIoVK5rdZ/HixVi0aJF3vra2FgkJCZg+ffoZP0xHsdvtyMjIwLRp05oNyELuL5Cu/gwAIE57DuPH3t3pZTrfnK0OqPOxDroH1oP/sQ78j3Xgf62pg7or1WfTpvAZHh4OqVSK4uJin+WlpaWIiopqdp+lS5figgsuwCOPPAIAGD58OLRaLSZNmoTnn38eMTExTfZRKpVQKpVNlsvl8i79Q9fs+fTFwFd3Ai4HMOw6SCfeC2kLwZvOXVfXOTXFOugeWA/+xzrwP9aB/52pDlpbN23qcKRQKJCWloaMjAyf5RkZGT6X4RsymUyQNBpsXSqVAnC3mPYoDhvw33mAoQSIHAzMfhVg8CQiIiJqtTb3dl+0aBHee+89rFy5EpmZmXjooYeQm5uLhQsXAnBfMr/tttu828+ePRtffvkl3nzzTZw6dQo7duzAAw88gLFjxyI2NrbjPklX2Ph/QN6vgDLQPZC8QuvvEhERERH1KG2+5/OGG25ARUUFnnvuORQVFWHo0KFYv349kpKSAABFRUU+Y37Onz8fer0er7/+Ov72t78hODgYl1xyCV566aWO+xRd4cBnwO9vu6eveQcI6+ff8hARERH1QO3qcHTPPffgnnvuaXbd+++/32TZ/fffj/vvv789p+oeiv8A/vdX9/RFjwADZvq3PEREREQ9FJ/tfjbmavdA8g4z0G8qMGWxv0tERERE1GMxfJ6J6HI/OrPqNBCcCMx5D5BI/V0qIiIioh6L4fMMJNtfBo7/AMhUwPUfAZpQfxeJiIiIqEdr1z2f54PImgOQ7HvFPXP5K0DsSL+Wh4iIiKg3YMtnc6qykZbzFgSIQNrtwKib/V0iIiIiol6BLZ+N2UyQrb0dgtMIV2waJDN72JBQRERERN0YWz4bq8kDjKWwygLgnLMKkDV9zCcRERERtQ/DZ2MRA+BYsAm/9l0EBPawJzARERERdXMMn83RRaFayycYEREREXU0hk8iIiIi6jIMn0RERETUZRg+iYiIiKjLMHwSERERUZdh+CQiIiKiLsPwSURERERdhuGTiIiIiLoMwycRERERdRmGTyIiIiLqMgyfRERERNRlGD6JiIiIqMswfBIRERFRl2H4JCIiIqIuw/BJRERERF2G4ZOIiIiIugzDJxERERF1GYZPIiIiIuoyDJ9ERERE1GUYPpuht9iRrfd3KYiIiIh6H5m/C9DdFFabccFLP0MCKRbYnZDL5f4uEhEREVGvwZbPRmKCVAjTKuAUBRwqrPV3cYiIiIh6FYbPRgRBwOjEYADA3txqv5aFiIiIqLdh+GwGwycRERFR52D4bEbD8CmKon8LQ0RERNSLMHw2Y3BMIGSCiCqTHafLjf4uDhEREVGvwfDZDKVMgkSde3p3TpV/C0NERETUizB8tiA5wH25fS/DJxEREVGHYfhsQV34ZMsnERERUcdh+GxBXfg8WWpAtcnm59IQERER9Q4Mny3QyYHkMA0AYG8uWz+JiIiIOgLD5xmMTgoGAOzOZvgkIiIi6ggMn2cwOiEYALCH930SERERdQiGzzOoG2z+QH417E6XfwtDRERE1AswfJ5B33AtgjVyWOwuHCms9XdxiIiIiHo8hs8zkEgEjE4MAcAhl4iIiIg6AsPnWaQlucPnnpxKP5eEiIiIqOdj+DyL+vBZBVEU/VwaIiIiop6N4fMsRsQHQyYRUFJrRX6V2d/FISIiIurRGD7PQq2QYkhcEAAONk9ERER0rhg+WyGtrtMRB5snIiIiOicMn62Q3qf+vk8iIiIiaj+Gz1ao63R0tLgWBqvDz6UhIiIi6rkYPlshKlCF+BA1XCKwj/d9EhEREbUbw2crNRxyiYiIiIjah+GzldIZPomIiIjOGcNnK6UlhQIA9uVWw+niYPNERERE7cHw2UoDogOgU8pgsDpwrFjv7+IQERER9UgMn60klQgYlRgMgM95JyIiImovhs82GJ3I+z6JiIiIzgXDZxvUDTa/m+GTiIiIqF0YPttgZEIwJAKQX2VGSa3F38UhIiIi6nEYPtsgQCXHgOhAALz0TkRERNQeDJ9txPE+iYiIiNqP4bON6p50xPs+iYiIiNqO4bON6sLn4YIamG1OP5eGiIiIqGdh+Gyj+BA1ogKVcLhEHMyv9ndxiIiIiHoUhs82EgSBl96JiIiI2qld4XP58uVITk6GSqVCWloatm3bdsbtrVYrnnzySSQlJUGpVKJfv35YuXJluwrcHdQ9530vwycRERFRm8jausNnn32GBx98EMuXL8cFF1yAt99+GzNnzsSRI0eQmJjY7D7XX389SkpKsGLFCvTv3x+lpaVwOBznXHh/qWv53JNbBZdLhEQi+LlERERERD1Dm8PnK6+8ggULFuDOO+8EACxbtgwbNmzAm2++iaVLlzbZ/ocffsCWLVtw6tQphIa6Wwz79OlzbqX2syGxgVDJJag22XGq3ID+kQH+LhIRERFRj9Cm8Gmz2bBnzx48/vjjPsunT5+OnTt3NrvPt99+i/T0dPzzn//ERx99BK1WiyuvvBJ///vfoVarm93HarXCarV652trawEAdrsddru9LUVul7pznOlcw+KCsCu7Cr+fKkdSiKrTy3S+aU0dUOdiHXQPrAf/Yx34H+vA/1pTB62tnzaFz/LycjidTkRFRfksj4qKQnFxcbP7nDp1Ctu3b4dKpcJXX32F8vJy3HPPPaisrGzxvs+lS5fi2WefbbJ848aN0Gg0bSnyOcnIyGhxXZBdAkCCb3b8AW3JwS4r0/nmTHVAXYN10D2wHvyPdeB/rAP/O1MdmEymVh2jzZfdAXeP74ZEUWyyrI7L5YIgCFi9ejWCgoIAuC/dX3vttXjjjTeabf1cvHgxFi1a5J2vra1FQkICpk+fjsDAwPYUuU3sdjsyMjIwbdo0yOXyZrdRHyvDjx/vQ5mow6xZF3Z6mc43rakD6lysg+6B9eB/rAP/Yx34X2vqoO5K9dm0KXyGh4dDKpU2aeUsLS1t0hpaJyYmBnFxcd7gCQCDBg2CKIrIz89HSkpKk32USiWUSmWT5XK5vEv/0J3pfGP7hgMATpWboLeJCNUquqxc55OurnNqinXQPbAe/I914H+sA/87Ux20tm7aNNSSQqFAWlpakybXjIwMTJw4sdl9LrjgAhQWFsJgMHiXHT9+HBKJBPHx8W05fbcSrFGgf6QOAIdcIiIiImqtNo/zuWjRIrz33ntYuXIlMjMz8dBDDyE3NxcLFy4E4L5kftttt3m3nzt3LsLCwnD77bfjyJEj2Lp1Kx555BHccccdLXY46inSEjnYPBEREVFbtPmezxtuuAEVFRV47rnnUFRUhKFDh2L9+vVISkoCABQVFSE3N9e7vU6nQ0ZGBu6//36kp6cjLCwM119/PZ5//vmO+xR+ktYnBJ/tzsOenEp/F4WIiIioR2hXh6N77rkH99xzT7Pr3n///SbLBg4c2Ct7qKV7Bps/kF8Dm8MFhYxPKyUiIiI6E6alc5AcrkWoVgGbw4U/Cmv8XRwiIiKibo/h8xwIgoDRnvs+2emIiIiI6OwYPs9R3XPed2czfBIRERGdDcPnOUrvU9/jXRRFP5eGiIiIqHtj+DxHw+KCIJcKKDdYkVdp9ndxiIiIiLo1hs9zpJJLMTTO/fSm3RxyiYiIiOiMGD47QN2QS3vY6YiIiIjojBg+O0AawycRERFRqzB8doDRnvB5rESPWovdz6UhIiIi6r4YPjtAZIAKiaEaiCKwL7fa38UhIiIi6rYYPjuI977PbHY6IiIiImoJw2cHSfOM97knl/d9EhEREbWE4bOD1HU62pdbDYfT5efSEBEREXVPDJ8dJDUyAAFKGUw2J44W6/1dHCIiIqJuieGzg0gkAkZxyCUiIiKiM2L47EB1nY52M3wSERERNYvhswPVhc+9DJ9EREREzWL47EAjEoIhlQgoqDajqMbs7+IQERERdTsMnx1Iq5RhUEwAAN73SURERNQchs8Olpboue8zm+GTiIiIqDGGzw6W1icUALCXg80TERERNcHw2cHqBps/XFgLk83h59IQERERdS8Mnx0sLliNmCAVnC4R+/Oq/V0cIiIiom6F4bMTpHHIJSIiIqJmMXx2gjQONk9ERETULIbPTpCe5Ol0lFMFl0v0c2mIiIiIug+Gz04wMCYAarkUtRYHTpYZ/F0cIiIiom6D4bMFDrH9PdXlUglGJgQD4HifRERERA0xfDZisBnw99/+jg+NH8Ilutp9nPQ+7vs++aQjIiIionoMn41UWirxffb3OOU4hf8e/2+7jzM6qS58VnZU0YiIiIh6PIbPRhIDE/HgqAcBAK/tfw3ZNdntOs5oz2M2sytMKDdYO6h0RERERD0bw2czrku5Dv1k/WBxWvDk9ifhcLX9/s8gtRypUToAvPROREREVIfhsxmCIOBqzdXQyXU4WH4Q7x9+v13HSfMMucTwSUREROTG8NmCYEkwHk17FADwxv43cKzyWJuPkZbETkdEREREDTF8nsHlyZfj4oSL4XA58MT2J2B32tu0f7onfB7Kr4HF7uyMIhIRERH1KAyfZyAIAp6e8DRClCE4XnUcbx54s037J4VpEK5TwOZ04XBhTSeVkoiIiKjnYPg8i3B1OJ6a8BQAYMUfK3Cw7GCr9xUEwdvrfcX207A72z9uKBEREVFvwPDZCtOSpuHyvpfDJbrw5PYnYXaYW73vLeOTIJUIWH+oGHd+sBsmW/ufnERERETU0zF8ttLisYsRqY5Edm02Xtv7Wqv3uyg1Au/dlg6VXIItx8tw07u/odJo68SSEhEREXVfDJ+tFKQMwrMXPAsA+DjzY/xe9Hur9714YCTW/Hk8gjVyHMirxrVv7UR+lamzikpERETUbTF8tsGFcRfi2tRrAQBP7XgKBpuh1fuOTgzBFwsnIDZIhVNlRsx5cyeOFes7q6hERERE3RLDZxs9nP4w4nRxKDQW4l+7/9WmfftHBmDtPROREqlDSa0V1721E7uy+ex3IiIiOn8wfLaRVq7F8xc8DwECvjzxJbbmb23T/jFBany+cALSk0JQa3Hglvd+Q8aRkk4qLREREVH3wvDZDunR6bh18K0AgGd2PoNqS3Wb9g/WKPDRgnG4dFAkrA4X7v5oNz79PbcTSkpERETUvTB8ttMDox9A36C+KDeX48XfXmzz/mqFFG/dkobr0+PhEoHHvzyEN34+CVEUO6G0RERERN0Dw2c7KaVKvHjhi5AKUnyf/T1+yP6hzceQSSV4ac5w3DOlHwDgXxuO4dn/HYHLxQBKREREvRPD5zkYEj4Efx7+ZwDA878+j3JzeZuPIQgCHr1sIJ6ZPRgA8P7ObNz/6T5YHXwWPBEREfU+DJ/n6K5hd2FQ6CDUWGuwZOeSdl82v/2CZLx20yjIpQLWHSzCHe/vgsHKpyERERFR78LweY7kUjleuPAFyCVybMnfgq9Pft3uY105IhYr54+BViHFjpMVuPGdX1Cmt3ZcYYmIiIj8jOGzA6SEpOC+UfcBAF7a9RIKDYXtPtaklAh8ctd4hGkV+KOgFte+tRO5FXwaEhEREfUODJ8dZN7geRgZMRJGuxFP7XgKLtHV7mMNjw/GF3+ZiPgQNXIqTLjmzZ04XFjTgaUlIiIi8g+Gzw4ilUjxwoUvQC1T4/fi3/HJ0U/O6XjJ4Vp8+ZeJGBQTiHKDFTe8/St2ZrW9QxMRERFRd8Lw2YESAxOxKG0RAGDZnmXIrsk+p+NFBqrw2d3jMS45FAarA/NX7sL6Q0UdUFIiIiIi/2D47GA3DLgBE2ImwOK04MkdT8LhOrce64EqOT64YywuGxINm9OFe9fsxVtbsmBztP+yPhEREZG/MHx2MEEQ8NwFzyFAHoCDZQfx/uH3z/mYKrkUb9w8GjePS4QoAv/4/igu/vdm/HdXHhxOhlAiIiLqORg+O0G0NhqPj3scAPDG/jdwrPLYOR9TKhHw/J+G4sWrhyEiQImCajMeXXsQ0/6zFd/sL4CTT0UiIiKiHoDhs5PM7jsbFydcDIfLgSe2P4FqS/U5H1MQBMwdl4itj1yMJ2cNQqhWgdPlRvz10/2Y+epW/PBHEZ8NT0RERN2azN8F6K0EQcDTE57G/tL9OF51HJM+m4QoTRRSQ1IxIHSA+z1kABIDEyGTtK0a1Aop/nxRX9w0LhEf7MzG21uycLzEgIUf78WQ2ED8bXoqLh4QCUEQOunTEREREbUPw2cnCleH41+T/4W///p35NTmoMRUghJTCbYVbPNuo5Qq0S+4HwaEDPAJpkHKoLMeX6eU4d6L++OW8UlYse0UVmw/jcOFtbjj/d0YlRiMv00bgAv6hzGEEhERUbfB8NnJxsWMw3dXfwe9TY8TVSdwvOo4jlUdw/Gq4zhRdQJmhxlHKo7gSMURn/2iNFE+LaSpoalICkiCVCJtco4gtRyLpg/A/AuS8fbWLHywMxv7cqtxy4rfMC45FA/PGIAxfUK76iMTERERtYjhs4sEKAIwOmo0RkeN9i5ziS7k6fPcgbTSHUiPVx1HgaHA20q6NX+rd3ulVIn+wf0xNnos5qTOQVJgks85QrUKLJ45CAsuTMbyn7Ow5rdc/Ha6Ete99QsuSo3A36alYkRCcFd9ZCIiIqImGD79SCJIkBSYhKTAJExLmuZdXtdKWtdCerzyOE5Uu1tJD1ccxuGKw1h1eBXGxYzD9anX4+LEiyGXyL37RwaosOTKIbjror54/eeT+O+uPGw9Xoatx8tw6aAoLJqWisGxgf74yERERHSeY/jshpprJXW6nMg35ONIxRH8L+t/2F6wHb8V/Ybfin5DmCoM16RcgzmpcxCni/PuExusxotXD8PCi/rh1Z9O4Kt9+fgxswQ/Zpbg8uExeOjSFPSPDPDHRyQiIqLzFMNnDyGVSL2tpDOTZ6LAUIC1x9fiyxNfosJSgXcPvYv3Dr2HC+IuwHWp1+Gi+Iu8vegTwzR4+foR+MsUdwj934FCrDtYhO8PFeFPI+Mwb2IfDI8PYsckIiIi6nQc57OHitPF4YHRDyDjugy8MuUVjI8ZDxEithdsx19//itmrJ2B5fuXo9hY7N2nf6QO/++mUfj+r5MwfXAUXCLw5b4CXPXGDsx6bTs+/CUbNWa7Hz8VERER9XYMnz2cXCLHtKRpeHf6u1h39TrcPuR2hChDUGoqxZsH3sSMtTNw/6b7sS1/G5wuJwBgUEwg3rktHd/edwH+NDIWCpkEmUW1ePqbwxj7wo9Y9Nl+/H66kgPWExERUYdrV/hcvnw5kpOToVKpkJaWhm3btp19JwA7duyATCbDyJEj23NaOovEwEQsSl+EH6/7ES9NeglpUWlwiS5sztuMe366B7O+nIV3D76LcnM5AGB4fDCW3TgKvz8xFc/MHowBUQGwOlz4cl8Brn/7F1z6yha8u/UUKgxW/34wIiIi6jXaHD4/++wzPPjgg3jyySexb98+TJo0CTNnzkRubu4Z96upqcFtt92GqVOntruw1DoKqQKz+s7C+5e9j2+u+ga3DLoFAYoAFBoL8dq+1zDt82lYtHkRfi36FS7RhWCNArdfkIwfHpyEr+6ZiBvSE6BRSJFVZsQL6zMxfulPuHfNXmw7UQYXnyFPRERE56DNHY5eeeUVLFiwAHfeeScAYNmyZdiwYQPefPNNLF26tMX97r77bsydOxdSqRRff/11uwtMbdM3uC8eG/sY/jr6r9iQvQGfH/8cB8oOICMnAxk5GYjXxWNi7ESkRaVhdNRojEqMxqjEEPzfFYPwvwNF+HRXLg7m12DdwSKsO1iEhFA1bkhPwHXpCYgKVPn74xEREVEP06bwabPZsGfPHjz++OM+y6dPn46dO3e2uN+qVauQlZWFjz/+GM8///xZz2O1WmG11l/qra2tBQDY7XbY7Z3fIabuHF1xrq4ihRSzkmZhVtIsHK86jrUn12L96fXIN+Tjv8f/i/8e/y8AIE4bh9GRozEqchTGpYzGtaPGIrNYj8/3FOCbA0XIqzTj3xuP4z8/nsCU1HBclxaHySnhkEk79vbh3lgHPQ3roHtgPfgf68D/WAf+15o6aG39CGIbepUUFhYiLi4OO3bswMSJE73LX3zxRXzwwQc4duxYk31OnDiBCy+8ENu2bUNqaiqWLFmCr7/+Gvv372/xPEuWLMGzzz7bZPmaNWug0WhaW1w6C6toRZY9C9nObOQ4clDoLIQI3z8OOkGHPrI+6CPrgzihDwprovBriQyn9PXDMgXJRYyLFDE+0oUwNoYSERGdl0wmE+bOnYuamhoEBrb8MJt2jfPZeDxIURSbHSPS6XRi7ty5ePbZZ5Gamtrq4y9evBiLFi3yztfW1iIhIQHTp08/44fpKHa7HRkZGZg2bRrkcvnZd+glDHYDDpYdxN6yvdhbuheHKw7D4DLgD/sf+MP+BwAgUBuIkeNGYoZmCIqKY7H5DyWqTS5sLBCQUShBelIIZgyOxPTBUYgJan8SPV/roDthHXQPrAf/Yx34H+vA/1pTB3VXqs+mTeEzPDwcUqkUxcXFPstLS0sRFRXVZHu9Xo/du3dj3759uO+++wAALpcLoihCJpNh48aNuOSSS5rsp1QqoVQqmyyXy+Vd+oeuq8/nbyHyEExOmozJSZMBAFanFYfKDmFPyR7sKdmD/WX7UWurxdaCrQDcz5xX91NjlHoQDNUJOJUfhV05CdiVXYXn1x/DiPggTB8SjcuGRqNfhK5dZTrf6qA7Yh10D6wH/2Md+B/rwP/OVAetrZs2hU+FQoG0tDRkZGTg6quv9i7PyMjAVVdd1WT7wMBAHDp0yGfZ8uXLsWnTJnzxxRdITk5uy+mpiymlSqRHpyM9Oh0AYHfZcbTiKPaW7sXukt3YW7IXtbZanNTvBaR7oUkCJJBC4YpHbU0sDtcm4uCmRPxrQyhSIgNw2dBozBgSjSGxgXyaEhER0XmqzZfdFy1ahFtvvRXp6emYMGEC3nnnHeTm5mLhwoUA3JfMCwoK8OGHH0IikWDo0KE++0dGRkKlUjVZTt2fXCLHsIhhGBYxDPOGzINLdOFk9UnsKdmDvSV7sadkD8rMZbBIcqAIyQFCfgEAiA4t8s0JePtAIpb/mohoVQpmDu6Dy4ZGY3RiCCQSBlEiIqLzRZvD5w033ICKigo899xzKCoqwtChQ7F+/XokJSUBAIqKis465if1DhJBgtSQVKSGpOKmgTdBFEUUGYtwsOwgDpQdwMHyg8isyIRdZoQs4ChkAUcBADWigDUFkfjoZCI0Yl9MSkjDnOGjMbFfBOQd3GueiIiIupd2dTi65557cM899zS77v333z/jvkuWLMGSJUvac1rq5gRBQKwuFrG6WFyWfBkAwOa04WjlURwsO4iDZQexv+wAioyFkKpKIFWVwIFd+Nn4GTZtV0LYlITkgMGY2icdcwaP8/OnISIios7QrvBJ1FoKqQLDI4ZjeMRw77JyczkOlB3AvpID2JG/F6drj8IptQLq4zjtOI73Tn6N904CMmcI3v36vxgU0Qf9QhIQp4tzh1ttLCI1kZBKpH78ZERERNQeDJ/U5cLV4ZiaOBVTE6fi4TGAw+XAscoTWHfsV2zN3YM8UyZcslI4pFXIMVUhJ+cgkON7DJkgQ5Q2qj6Q6mLd01r3dKQmEjIJ/3gTERF1N/zbmfxOJpFhSPggDAkfhEcvuB2iKGL7yWws//FbFAt2FBgKIcirIJFXQSKvhkReDQccKDAUoMBQ0OwxpYIU0dpob0tpnC4O42LGYWTkSEgE3ldKRETkLwyf1O0IgoDxfeJRGdsHs2bNQq3VhW0nyrH5WCm2nihHpdECQaaHRF4FQV6FqFATIkKMUKiqYXCWo8hYCIeraThdfmA5YrWxmNV3Fi5Pvhz9Q/r78VMSERGdnxg+qdsL0ynxp1Fx+NOoODhdIg7mV2PzsTJsPl6Gg/nVKKgFCrLd2wYoZbigfyjSUqToG2OHWSxDoaEQJ6tPYkveFhQaC/Heoffw3qH3MCBkAGb1nYVZybMQrY3262ckIiI6XzB8Uo8ilQgYlRiCUYkheGhaKioM1katojb8cLgUPxx2bz8oJghTBvTHnNQ5eHLs0/ileDvWnVqH7QXbcazqGI7tOYZle5YhLSoNl/e9HNOSpiFIGeTfD0lERNSLMXxSj3a2VtHMolpkFtXizc1ZUMgkGBEfhLSke7FkxP2oEvZgc8EG7CnZg90lu7G7ZDde/O1FTIqbhFl9Z2Fy/GSoZO1/Pj0RERE1xfBJvUZrWkV3ZVdhV3aVZ49A9IuYj4sTboMQsB9Z5q3I0WdhU94mbMrbBJ1ch6mJU3F538sxNnosh3YiIiLqAAyf1Gs1bBUVRRGnyo3Yk12F3TmV2JNThawyo+cFAAMADEBIcDkiYo5AL90Fg70M32R9g2+yvkGEOgKXJV+Gy5Mvx+CwwXw2PRERUTsxfNJ5QRAE9IvQoV+EDtePSQAAVBpt2JtThd05VdiTU4kD+TWoqg5HVfVFAC6EVJ0DZfAByIMOocxcho+OfISPjnyEPoF9MDVxKgaGDcTAkIFICEhgqygREVErMXzSeStUq8Clg6Nw6eAoAIDV4cQfBbWeQFqJPTkqlBclA0VXQKo7DnngfsgCMpFdm40Vf6zwHkclVSElJAUDQgdgQMgADAgdgNSQVGjlWn99tG7nVPUp/JD9A2K0Mbii3xWQS+T+LhIREfkJwyeRh1ImRVpSCNKSQvBn9IUoisipMHlaRpOxJ2csjp+ogEx3BFLNaUhVRZAoi2GBBYfKD+FQ+SGf48Vp4zEwrD6QDggdgFht7Hlzyd7pcmJr/lasOboGvxb96l2+8o+VeGD0A7g08dLz5rsgIqJ6DJ9ELRAEAX3CtegTrsW1afEAgBqTHXtzL8QfBTU4WqxHZnE1cmpzISiKIFEVQaoqhERZBIm8FgXGfBQY8/FT7k/eY2pkOgwITcXABq2k/YP796pe9TXWGnx14it8euxT7yD/EkGCibETcaTiCLJrs7Fo8yIMDx+Oh9IeQnp0up9LTEREXYnhk6gNgjRyXDwwEhcPjPQus9idOFlqwNFiPY4V1+JosR5HC4tRac92B1KlO5hKlKUwOQzYV7oX+0r3evcXICBUFYZYXQyitdGI0kQhWhtd/9JEI1wd3u3vKz1RdQJrjq7BulPrYHaYAQCBikDMSZmDGwbegDhdHAw2A94//D4+PPIhDpYfxO0bbsfk+Ml4cPSDfOIUEdF5guGT6Byp5FIMjQvC0DjfwekrjTYcLa7FsWI9jhXrkVlcheOVWbBLCzyX7D2hVGZEhaUcFZbyJpfu60gFKSI0EYjWRDcJptHaaERpoxCqCu3y59Y7XA5sztuMNUfXYFfxLu/y1JBUzB04F7P6zoJapvYu1yl0uG/UfbhhwA1468BbWHtiLbbkb8G2gm24st+VuHfkvXzaFBFRL8fwSdRJQrUKTOwXjon9wr3LXK6LkFdl8rSS6nG0qBZHSgqRZyiEIKuGIKuBRF7jnpbXQKaoAaS1cMKJYmMxio3FQFnz55NL5IjSRCExMBEpwSlIDU1Fakgq+gb1hUKq6NDPVm2pxtoTa/HZsc9QZCwC4A7IlyRegrkD5yItKu2M93NGaCLw1ISncMvgW/D/9v0/ZORk4OuTX+P7099j7qC5WDB0AZ80RUTUSzF8EnUhiURAUpgWSWFazBhS18KXBqPVgcyiWhwurMXhwhocLqzF8Xw9zE4RgAuCTO8JptWQK2sRGmSCRmOAIKuG2VWBGlsl7C478g35yDfkY2fhTu85pYIUfQL7IDUkFSkhKUgNcYfSaG10mzv8HK08ijWZa7D+9HpYnVYAQIgyBNemXovrB1zf5lbL5KBkvDLlFRwoO4BXdr+CvaV7seqPVVh7fC3+POzPuGnQTVBKlW06JhERdW8Mn0TdgFYpQ3qfUKT3CfUuszlcOFGqx+HCWhzxhNIjhbUw6p0oKPfdXyI40SfKiYRIK4ICq+CSF6HKnoNs/UnU2mqRVZOFrJosfJ/9vXefAHkAUkJSfAJp/+D+0Cl0Pse2u+zYlL0JazLXYG+De1UHhQ7C3EFzMTN55jkHxBERI/D+Ze9ja/5WLNu7DCerT+LlPS9jzdE1uG/Ufbg8+fJuf88rERG1DsMnUTelkEkwJDYIQ2LrLz+7XCJyKk3e1lF3MK1BucGGU8VSnCpWAAgAkAhgHAJUUvSPdiE8rAJKTSmskgKUWU8jpzYbersee0v3+gRKAIjTxSElJAX9A/sjy5yF1755DaXmUgCATJBhWtI0zB00FyMiRnToUEmCIGBywmRcGHchvs36Fq/vfx1FxiI8uf1JvH/4fTw0+iFcGHchh2ciaqDWVgutTMt/nFGPwvBJ1INIJAKSw7VIDtfiiuGxAABRFFGqt7oDaYG7t/2xEj1OlxuhtzixLxtAdiiAUAADAQBRgTKkRBsRHFwOibIIRjEfhaZTKDWXosBQgAJDATZjs/e8oapQXJd6Ha4fcD0iNZGNi9WhpBIprk65GjOTZ2J15mqsOLQCJ6pO4J6f7sHY6LF4KO0hDA0f2qllIOru9pXuw9sH3saOwh0IVYViUtwkTEmYgomxE6GRa/xdPKIzYvgk6uEEQUBUoApRgSpcMjDKu9xid+JUmRHHSmpxrNiAY56e94U1FpTUOlBSqwQQ53mlQyIAieFAbGQ1tLoyOGQFqKzOwbyxc3FF/1kd3mnpbFQyFRYMW4A5KXPw3qH3sOboGvxe/DtuWncTZvSZgYXDFyIuIA4qqapLW0NFUUStrRYVlgpUmitRYalAhbkClZb6aZPdBKfohEt0QYTofhfd707R6V3mXQ6Xd77xMgECVFYV9v6+F/1D+qNfUD/0De6LKE0UW4HPM6IoYnfJbrx94G38Vvybd3mlpRLfZH2Db7K+gVwix9iYsZgSPwVTEqZw9Ajqlhg+iXoplVyKwbGBGBwb6LO81mLHcU/raN0wUMdK9Kg22ZFdBmSXBQMIBpACAHjiuAQfRP2OgdGBGBQTgIExgRgUHYggTdc8IjNYFYyHxzyMuYPm4vV9r+O7U99hQ/YGbMjeAMB9K4BWoYVOroNW7n7XKXTud7kOWoUWAfIAaOVaBCgCmmyjlWuhlWthsBtQYa5oNkxWWiq96yotlXC4HF3y2RvKOZnjM6+Va9E3qC+Sg5LRL7gf+gb1Rb+gfojVxfISbC8jiiJ+KfoFbx9423ubjEwiw1X9rsK8IfNQZirDz3k/Y0v+FuTp87CjYAd2FOzAC7+9gIGhAzE5fjIuTrgYg8IGdflwbETNYfgkOs8EquRNOjeJoogyvRVHi/U4XqKvHzC/sAYWuwsH8mtwIL/G5zixQSoMjAnEwOgADIpxB9M+YVrIpJ3zl1usLhYvTnoR84bMw6t7X8WOwh1wiS44RAdqrDWosdac/SAdKEAegFB1KMJUYQhThyFUVT+tk+sgkUgggQQSwfclQHC/C+73xtsIguBdJggCrDYr/rf9fwhMDkSOPgdZNVnIq82D0W5s9rGuSqkSfQL7oG9wX3cg9QTTxIBEyKVd8w8G6hiiKGJbwTa8feBtHCw/CMA9pNo1KddgwdAFiNHFAHCPGjE2ZiweHfMoTtWcwua8zdiSvwUHyg7gaOVRHK08ircPvo0IdQQmJ0zGlPgpGBczrlc9WY16FoZPIoIgCIgMVCEyUIWLUiMAAHa7Hd+tW4/BYyfjZLkZmUW1OFpci8wiPQqqzSissaCwxoJNR0u9x1HKJEiNCvAG0oExARgUHYgQbcddsh8QOgDLL10OURRhdpiht+lhtBthsBtgsBlgsBtgtBu9y/V2z3rPOoPdAKOtfrnRbnR/BxAQogpxh8hGYbLhe6gqFKHq0C4bAsputyNXkYtZI2ZBLneHR7vTjlx9Lk7VnEJWdRZO1ZzCqepTOF1zGlanFceqjuFY1TGf48gEGRICExCliYJKqoJSpoRSqvROq6Qq97zM/e59NbNOJVVBIVVAI9dAJ9d1y8v/LtHVY1v5XKILP+f+jLcPvo3MykwA7n9UXJd6HeYPmY8obVSz+wmCgH7B/dAvuB8WDFuASksltuVvw5b8LdhRsANl5jJ8cfwLfHH8C6ikKoyPHY8p8VMwOWEywtXhzR6TqDMwfBJRiyQC0DdCiwGxwbh8eIx3eY3Z7h4kv7gWmUXuQHqsWA+z3YlDBTU4VODbChkdqMLAmAD0DdchIVSN+BCN912nbN//hgRBgEauOefOFS7RBZPdBJVMBZmkZ/wvUS6Ve0PGtKRp3uVOlxOFhkJk1WR5g+npmtPIqs6CyWHC6ZrTOF1zukPLopPrEKuLRZwuzvcV4H7XyrUder46epsehYZCFBgKmn03O80YETEC42LGYULMBAwJHwK5pHu3/DpdTmTkZuCdg+/gRNUJAIBapsaNA27EbUNua3NADFWF4qr+V+Gq/lfB5rRhV/EubM7bjM35m1FsLHZP520GfgGGhQ9zX55PvBgpwSnd8h8U1Hv0jP/TElG3EqSWY2xyKMYm11+6rxsG6mhRLTKL9d6W0rxKM4prLSiutWDzsaaPZwrRyL1hNCFEg/gQNeJDNUgIcYdTlbxz71+UCJImY5v2VFKJFAmBCUgITMCUhCne5aIoosRUglPVp1BhqYDVaYXVaYXFYYHNaYPFafHON1xndVrd6xzWJtNWpxVO0QmD3YDjVcdxvOp4s2UKVgYjTheHWF0s4nXx3mBaF1hbakE22o3ukRf0BSg01ofKuoBZa6s96/exp2QP9pTswfL9y6GVa5EelY7xMeMxLmYc+gf37zYBy+Fy4IfsH/DOwXe8/zjQyrWYO3Aubh18K0JUIed8DoVUgQviLsAFcRfgCfEJHK867g2ff1T84b2F4/X9r6NPYB9M7zMdM/rMYBClTsHwSUQdouEwUDOH1beS6i12z7Pt9citMCKv0oz8ahPyKs2oMdtRZbKjytS0tbROuE5Z31oaovYJqnEhasg76R7T3kQQBERrozu857PJbkKxsRj5hnyflsd8fT4KjYWosdag2lqNams1DlccbvYYEeoIbxC1OW3u43j2PZtQVShitbHe/WN1sd6QKwgCdhXvwq9Fv+L34t9RY63Blvwt2JK/BQAQrg7H2OixGB8zHuNjxnvvn+xKdpcd32V9h/cOvYdcfS4AIEARgFsH3Yq5g+Z22iNmBUHAgNABGBA6AHePuBtlpjJszd+KzXmbsbNwJ7Jrs/HOwXfwzsF3vEF0etJ0pIakMoh2shprDUx2k1/+PHYlhk8i6lQBzXRwqlNrsSO/0oz8KhPyqjzvnvn8KjMMVgfKDVaUG6zYl1vdZH+ZREB8iBpJYe7QmxSmQZ8wLfqEaxHPYNrpNHKNu2NTcN9m1xtsBu+4sXXhtC6oFugLYHKYUGYuQ5m5DAfKDjTZP1gZ7HNJ3xsyPYHzbLdcJAcl4/oB18MlunC08ih+K/oNvxb9ir0le1FuLsf60+ux/vR6AEBSYJK3VXRs9NhOC34AYHPa8E3WN1hxaAUKDAXezzpvyDzcOODGLm+Jj9BEYE7qHMxJnQODzYDN+ZuxMXsjdhTsYBDtZNWWauwp2YNdJbuwq3gXTlSdgAgRaVFpuHXwrZgSP6VXjl7B8ElEfhOokmNwrLzJcFCA+1JxjdmOvEoz8qpMPsE0r8qMvEoTrA4XsitMyK4wYctx30v60gbBtI83lGqQFKZFQogGChmDaWfTKXTeFrbGRFFEjbXGJ5jKpXLE6+K9LZgddb+oRJBgcNhgDA4bjNuH3g6b04YDZQfwS+Ev+K34N/xR/gdyanOQU5uDz459BgECBoUN8obRYSHDvMdyupzeWxAsDkv9e4PputsWzA6zd7rh9jsKdqDEVAIACFOFYf6Q+bh+wPXdYnB4nUKHK/pegSv6XgGDzYAt+VuwIXtDs0F0WtI0zOgzg0G0DaosVe6wWbwLu0p2ee/tbUgiSLy3jMTr4nHzoJvxp/5/6jW3BwEMn0TUTQmCgGCNAsEaBYbFN22FcrlElOgtyC43IbvCiOwKI3IaTFvsLuRUmJBTYcLWRvtKBCAuRO0OpGHuFtOEUA3igt2X8wPVMv5l2skEQUCwKhjBqmAMCR/SpedWSBUYEz0GY6LHAHB3XtpdvBu/Fv2K34p+Q1ZNFo5UHMGRiiNY+cdKyCVySEUpnvv0Odhctg4pQ6Q6EncMuwNzUuZ02yGPdAodLu97OS7ve7k3iG7M3ojtBduRXZuNdw+9i3cPvcsgegaVlkpv2NxdsrvZsNk/uD/SotIwJnoM0qLS4HA58Nmxz/D58c+Rb8jHS7tewhv738DVKVdj7sC5iA+I98Mn6VgMn0TUI0kkAmKC1IgJUmNCvzCfdXWPHM0uN3rCqAk5FUacLne/m2xOd4tqpRnbTpQ3ObZOKUNcsBrxIWrEhagRF+x+jw9xB9RwnYJ/wfYiAYoAXJx4MS5OvBgAUGoq9V6i/7XoV5SaSmGHHRB996sbjkolU0EtU9dPS9XeIapUMlX9u2c6WhuN6X2md9lwXR2BQbR1Ki2V2F282xs2T1afbLJN/+D+SI9K94bNMHVYk23+OvqvuGv4Xfhf1v/w0ZGPkF2bjY+OfITVmatxScIluHXwrRgVOarHfr8Mn0TU6zR85Oi4vk2DaZnB6m0xzakwIrvchPxqMwqqTCg32GCwOtxPgCrRN3t8pUzSIJA2DadRgSpIJT3zLwUCIjWRmN1vNmb3mw1RFJFdnY2ffv4J0y+ZjgBVgDdk9tRxRM9Va4NonC4OgQr3LTWiJ7mLolg/DRGiWJ/oz7bOZXJhx84d6BPUBwkBCUgISEBiYCJClCFdHsIcLgfKTGUoNhWjwFCAA6UHzhg261ra06LSEKpqev97c9QyNa4fcD2uTb0WOwp24OPMj7GzcCd+zP0RP+b+iCFhQ3DL4FswI2lGj3uABMMnEZ1XBEFAZIAKkQEqn6Gi6ljsThRUm5FfZUZBlRkF1aYG0+5ho6wOF06VG3Gq3NjsOaQSAZEBSkQFqhAdqEJ0kOcV6Pve2cNI0bkTBAHxunhESCMQo43xDvRPbg2DqNFuxOa8zd4gWmAoQAEKOvR8edl5TZZp5VokBiT6BNK66UhNZJv/kSCKIiotlSg2FrtfJvd7kbHIu6zMXAaX6Gp2/5SQFIyJGoP06PQ2hc2WSAQJJsVPwqT4SThZdRIfZ36M7059h8MVh7F422L8Z/d/cOPAG3Ft6rUdMixXV2D4JCJqQCWXol+EDv0imr+53+ZwobjGgvxqEwqqPCG12h1O86tNKKq2wOESUVRjQVGN5YznCtbIfQJpVKAKMUEqRHnmY4JU0PD/0tRDaOVanyB6oOwAnC6nt1VS8PznmfFOC0L9cgGCTytm3XKH04Gfdv6EyNRIFBgLkKvPRZ4+D8XGYhjtRmRWZnqfBtWQUqpEvC7ePf5tQII3pIapw7wtl0WGIpSYSrwBs8RY0qp7e2USGaI0UYjWRmNAyABvy2ZnBsD+If2xZOISPDD6AXxx/At8evRTlJpL8dq+1/D2wbcxu99s3Dro1hZHoOgu+L81IqI2UMgkSAzTIDGs+Z7JTpeIMr3VPbB+jQUlte4QWuKZr1tutjtRbbKj2mTH0eLmL+8DgEouQaBUiv+W7vF2iqq7DzU2WI2YIBVkHFKKuhmtXIuJsRM77Hh2ux0lihLMGjzLp/XZ6rSiQO8Oo7m17kBa9yowFMDqtCKrJgtZNVltOp8AAeHqcO/4uNHaaERr3O8x2hhEa6MRpg7z260XoapQ3DX8Ltw+5Hb8kP0DPjryETIrM72PT70g9gLcOvhWTIyd2C3vC2X4JCLqQFKJ4L3MjoTmtxFFEbVmh/fJT8U1ZhTXWOuna60orjGjymSHxe6CxS6gNKsCyKpociyJ4H58acOOUXHBGs+7CnHBGqgVvLxPvZNSqmxxrFmHy4EiYxHyavO8LaW5+lzk6/NRaalEuDrcGyQbB8woTVSPuI9SLpVjdr/ZuKLvFdhTsgcfZ36MTbmbsKNwB3YU7kDfoL64ZfAtuDbl2m4VQhk+iYi6mCAICNLIEaSRY0B0QIvbWexO5Fca8PWGLYgfMBzFepv33tOCajOKqi2wOV0orLGgsMaCXahq9jihWoU7mHpaS2ODVYgLViPGMx2uVULCDlLUy8gkMu+9nxPRca2w3ZEgCEiPTkd6dDry9HlYk7kGX538CqdqTuH709/jutTr/F1EHwyfRETdlEouRVKoBilBImaNjmvS2cXlcvfcz68yo7C6/t7Thu8GqwOVRhsqjbYWH2GqkEoQHaRCbLDKHU6D6kNqrCew6pT864KoJ0gISMBjYx/DvSPvxVcnv0L/4P7+LlIT/L8JEVEPJZHUDymVltS0k0Pd5f38ahMKqy0oqDKhsMbiaTU1o7DaghK9u/U0t9KE3EpTi+cKVMm8QTQ2WIWYIPd73fmjA1XQMqASdRs6hQ63Dr7V38VoFv9PQUTUS9Vf3g/CkNjmn1Vud7pQUmtBYbUFhdVmFNa4W1GLqt0htbDajFqLw/0q1p+xc5ROKUNkoBJRASpEBbqHmooMrOvJ756PCFByiCmi8xzDJxHReUwulSA+RIP4kJafK26wOtwtpTWegOppNS2sNqNUb0FprRV6qwMGqwOGMgdOlTU//mmdYI0cUQEqRAYqvUNMRQUqGwRVFcJ1CvbiJ+qlGD6JiOiMdEoZUqICkBLVcucog9WB0loLSmqtKNW7h5YqqbV63uunrQ6Xd4iplp4gBbh78YfrlN7L+lENg2pQ/XyQWt6tevES0dkxfBIR0TnTKWXQRejQt4XB+YH6e1BLmgmnxTUWlOrd86V6K5wuEaV6K0r11hY7SgHuR51GNbis721FDVAhWCNHsEaBYLUcwRo5AlRyPvaUqBtg+CQioi7RcIip1DO0ojpdIiqMVpTWWt0D9estKPEM0N8wsFaZ7LA6zt5Zqv78QKDKHUSD1XIEqn3DaVCjefcyBZ8yRdTB+JMiIqJuRSoREBmgQmSACkPjmu8oBbjHQa17mlTD1tPiGgvK9FbUmO2oMdtRbbLBaHNCFOFdltPGMmlkUrx5aidigtWIDlIj1vMggZggteedvf2JWou/FCIi6pFUcikSQjVICG25s1Qdm8PlCZ42VJvqQqkd1WY7akw2VDecb7CsxmyHKAImh4CjJQYcLTG0eI4AlQwxQSpEB6kRE6jyhlL3GKrukBqglPEeVTrvMXwSEVGvp5BJEBGgRESAsk37uVwiKvRmrF2fgZQRY1FmsKOoxt3KWuR5HGpRtQV6qwN6iwN6iwHHzxBQtQopIgNV3kv/IRoFgjTu94b3qNbPy6FjYKVehuGTiIioBRKJgGCNHDEa4KKU8CZPmaqjt9hRUmtBUY2lPpzWWFBUY/ZO15jtMNqcOF1+5qGoGpN5ylB3T2qI517UEI0cIVoFogJV9Y9MDVJDIeMQVdS9MXwSERGdowCVuzd9/8iWO1KZbA7vfanuS/82VHmGnaox21BltKPac1tAtcmOKpMNVocLDpeIcoMN5QYbgDMHV0EAInRKxAarEdfgEalxnqdTxQWrEazh8FTkXwyfREREXUCjkKHvWYajasxid3qDqDuUuu9FrTLZUGOyo9JoQ3Gt+2lUBVVmWB0u7xBV+/Oqmz2mWi71CaVx3semqhEZqESw2t3KykH+qbMwfBIREXVTKrkU0UFSRAepzrqtKIqoNNpQ2ODRqHWPTC2oMqOg2oJygxVmuxNZZUZkneVJVDqlDEHqusv99e+BajmC1Qqf5Q234z2qdDa9Knw6nU7Y7fZzPo7dbodMJoPFYoHT6eyAklFbdVYdKBQKSCT81zwR9T6CICBMp0SYTolh8c0PUWWxO1HseUxqgecxqQXVJm9gLTdYobc4ALifWmWwOlBQbW5TOaQSwRtGQzydqUK09feohmjqXnKEat3rgtnSel7pFeFTFEUUFxejurq6w44XHR2NvLw8/uvNTzqrDiQSCZKTk6FQKDrsmEREPYVKLkWfcC36hGtb3MbhdEFvcXiHmqo22RqMmer7XmO2+QxbZXO44HS5W2ArjTacbkPZAlWyBuG0PqiGahUIUEqQXSEgOrcaMcFahAcooFH0ighzXuoVNVcXPCMjI6HRaM45rLhcLhgMBuh0OraS+Uln1IHL5UJhYSGKioqQmJjIf1gQETVDJpW4g5+27f9It9id9WHU5O5QVWWyuV9Gz7zRM+9ZVzeWaq3FgVqLAzkVLT2tSoqVx3/3zmkVUoQHKBGhUyJc5x5Gq/5d4TOvkkvb+W1QZ+jx4dPpdHqDZ1hYWIcc0+VywWazQaVSMXz6SWfVQUREBAoLC+FwOFocMoWIiNpHJZdCJZciKvDs96jWcbpE1JjdnaeqTTbPux2VDUJrhcGKrPxSOOQalBussNhdMNqcMFaYzhBW6wUoZU3CaahWiVCdAmFad+tq3XuwRgGphI0TnanHh8+6ezw1mrM/4YKo7nK70+lk+CQi6gakEgGhnuDXErvdjvXr12PWrEmQyWQw2pwo11tRZrCiTG9FeaP3MoPNu97mcLkfAmB14FQrxlgVBHgv9zcMpQ1fYVql+13nvjWAY6u2TY8Pn3V4CZVag39OiIh6NkEQoFPKoFPKznjvKuDuP1BrcTQJp+UGKyqNNlQYbN77UyuM9bcA1C1rrQClrEmnqmCNHKEaBYK1CoRqmq47n28F6DXhk4iIiKghQajved+vFeOr2p0uVHku/Vca3IG0LphWGpsG1iqTDS4R3pbV3MrWl02jkHpGAqh7nKoCoZ6hq7RKmeclhVYhq59XSD3v7nU9dYQAhk8/mTJlCkaOHIlly5b5uyhEREQEQC6VIDJAhciA1t2z6nKJ3kH/vR2qmu1cVfc0K/e70yXCZHPCZDO3eSirhhQyCXRKGTQKqfdd62kV1ihk0CmlGBAdiLnjEtt9js7A8ElERETUDpKG96tGtG4fl0uE3urwDabG+lEBasx2mKxOGKwOmGx17w4YrU4YbQ4YrQ7YnSIAwOZwodJhQ+UZbmW9eEAEwycRERHR+UrSYBD+PjjzPastsTlcMFodnjBaH0qNVieMnrBqsDphsjmQFNa+c3SmnnmzQC9TVVWF2267DSEhIdBoNJg5cyZOnDjhXZ+Tk4PZs2cjJCQEWq0WQ4YMwfr167373nzzzYiIiIBarUZKSgpWrVrlr49CREREnUwhc4/FGh+iwYDoAIxODMGklAhcNjQac9LiceuEPvjLlH742/QBuDYt3t/FbaLXtXyKogiz/dwex+hyuWC2OSGzOdo0xqRaLm1Xb+r58+fjxIkT+PbbbxEYGIjHHnsMs2bNwpEjRyCXy3HvvffCZrNh69at0Gq1OHLkCHQ6943TTz31FI4cOYLvv/8e4eHhOHnyJMzm9t8/QkRERNSZel34NNudGPz0Br+c+8hzM9r8uK+60Lljxw5MnDgRALB69WokJCTg66+/xnXXXYfc3FzMmTMHw4YNAwD07dvXu39ubi5GjRqF9PR0AECfPn065sMQERERdQJedvezzMxMyGQyjBs3zrssLCwMAwYMQGZmJgDggQcewPPPP48LLrgAzzzzDA4ePOjd9i9/+Qs+/fRTjBw5Eo8++ih27tzZ5Z+BiIiIqLV6XcunWi7FkedmnNMxXC4X9LV6BAQGtPmye1uJotji8rpL+HfeeSdmzJiBdevWYePGjVi6dClefvll3H///Zg5cyZycnKwbt06/Pjjj5g6dSruvfde/Pvf/25zWYiIiIg6W7taPpcvX47k5GSoVCqkpaVh27ZtLW775ZdfYtq0aYiIiEBgYCAmTJiADRs677K4IAjQKGTn/FIrpG3epz33ew4ePBgOhwO//fabd1lFRQWOHz+OQYMGeZclJCRg4cKF+PLLL/G3v/0N7777rnddREQE5s+fj48//hjLli3DO++8c25fIhEREVEnaXP4/Oyzz/Dggw/iySefxL59+zBp0iTMnDkTubm5zW6/detWTJs2DevXr8eePXtw8cUXY/bs2di3b985F743SElJwVVXXYU///nP2L59Ow4cOIBbbrkFcXFxuOqqqwAADz74IDZs2IDTp09j79692LRpkzeYPv300/jmm29w8uRJHD58GN99951PaCUiIiLqTtocPl955RUsWLAAd955JwYNGoRly5YhISEBb775ZrPbL1u2DI8++ijGjBmDlJQUvPjii0hJScH//ve/cy58b7Fq1SqkpaXhiiuuwIQJEyCKItavXw+5XA4AcDqduPfeezFo0CBcdtllGDBgAJYvXw4AUCgUWLx4MYYPH46LLroIUqkUn376qT8/DhEREVGL2nTPp81mw549e/D444/7LJ8+fXqrO7q4XC7o9XqEhoa2uI3VaoXVavXO19bWAgDsdjvsdrvPtna7HaIowuVyweVytfajnFHdfZh1x+0MmzZtAuD+PoKCgvD+++832abu3K+++ipeffXVZtc/8cQTeOKJJ1rct6fqrDpwuVwQRRF2ux1Sadvv0T2f1P3WGv/mqGuxHvyPdeB/rAP/a00dtLZ+2hQ+y8vL4XQ6ERUV5bM8KioKxcXFrTrGyy+/DKPRiOuvv77FbZYuXYpnn322yfKNGzdCo9H4LJPJZIiOjobBYIDNZmtVGVpLr9d36PGo7Tq6Dmw2G8xmM7Zu3QqHw9Ghx+6tMjIy/F0EAuuhO2Ad+B/rwP/OVAcmk6lVx2hXb/fGHWsa9sw+k08++QRLlizBN998g8jIyBa3W7x4MRYtWuSdr62tRUJCAqZPn47AwECfbS0WC/Ly8qDT6aBSqdr4SZoniiL0ej0CAgLa1YmIzl1n1YHFYoFarcZFF13UYX9eeiu73Y6MjAxMmzbNewsIdT3Wg/+xDvyPdeB/ramDuivVZ9Om8BkeHg6pVNqklbO0tLRJa2hjn332GRYsWIDPP/8cl1566Rm3VSqVUCqVTZbL5fImH9jpdEIQBEgkkjYNi3QmdZd5645LXa+z6kAikUAQhGb/LFHz+F11D6wH/2Md+B/rwP/OVAetrZs2/a2uUCiQlpbWpMk1IyPD+3Se5nzyySeYP38+1qxZg8svv7wtpyQiIiKiXqTNl90XLVqEW2+9Fenp6ZgwYQLeeecd5ObmYuHChQDcl8wLCgrw4YcfAnAHz9tuuw2vvvoqxo8f7201VavVCAoK6sCPQkRERETdXZvD5w033ICKigo899xzKCoqwtChQ7F+/XokJSUBAIqKinzG/Hz77bfhcDhw77334t577/UunzdvXrM9vImIiIio92pXh6N77rkH99xzT7PrGgfKzZs3t+cURERERNQLsTcNEREREXUZhk8iIiIi6jIMn0RERETUZRg+iYiIiKjLMHySF5+ZS0RERJ2N4dOPfvjhB1x44YUIDg5GWFgYrrjiCmRlZXnX5+fn48Ybb0RoaCi0Wi3S09Px22+/edd/++23SE9Ph0qlQnh4OK655hrvOkEQ8PXXX/ucLzg42DsaQXZ2NgRBwH//+19MmTIFKpUKH3/8MSoqKnDTTTchPj4eGo0Gw4YNwyeffOJzHJfLhZdeegn9+/eHUqlEYmIiXnjhBQDAJZdcgvvuu89n+4qKCiiVSmzatKkjvjYiIiLqwXpf+BRFwGY895fd1PZ9RLFNRTUajVi0aBF27dqFn376CRKJBFdffTVcLhcMBgMmT56MwsJCfPvttzhw4AAeffRR72Mn161bh2uuuQaXX3459u3bh59++gnp6elt/roee+wxPPDAA8jMzMSMGTNgsViQlpaG7777Dn/88Qfuuusu3HrrrT6hd/HixXjppZfw1FNP4ciRI1izZo338ap33nkn1qxZA6vV6t1+9erViI2NxcUXX9zm8hEREVHv0q5xPrs1uwl4MfacDiEBENyeHZ8oBBTaVm8+Z84cn/kVK1YgMjISR44cwc6dO1FWVoZdu3YhNDQUANC/f3/vti+88AJuvPFGPPvss95lI0aMaHORH3zwQZ8WUwB4+OGHvdP3338/fvjhB3z++ecYN24c9Ho9Xn31Vbz++uuYN28eAKBfv3648MILvZ/p/vvvxzfffIPrr78eALBq1SrMnz8fgiC0uXxERETUu/S+ls8eJCsrC3PnzkXfvn0RGBiI5ORkAEBubi7279+PUaNGeYNnY/v378fUqVPPuQyNW0udTideeOEFDB8+HGFhYdDpdNi4caP3qVWZmZmwWq0tnlupVOKWW27BypUrveU8cOAA5s+ff85lJSIiop6v97V8yjXuFshz4HK5UKvXIzAgABJJG/K5XNOm88yePRsJCQl49913ERsbC5fLhaFDh8Jms0GtVp9x37OtFwQBYqPbAJrrUKTV+rbUvvzyy/jPf/6DZcuWYdiwYdBqtXjwwQdhs9ladV7Afel95MiRyM/Px8qVKzF16lTv41eJiIjo/Nb7Wj4FwX3p+1xfck3b92nDZeWKigpkZmbi//7v/zB16lQMGjQIVVVV3vXDhw/H/v37UVlZ2ez+w4cPx08//dTi8SMiIlBUVOSdP3HiBEwm01nLtW3bNlx11VW45ZZbMGLECPTt2xcnTpzwrk9JSYFarT7juYcNG4b09HS8++67WLNmDe64446znpeIiIjOD70vfPYQISEhCAsLwzvvvIOTJ09i06ZNWLRokXf9TTfdhOjoaPzpT3/Cjh07cOrUKaxduxa//PILAOCZZ57BJ598gmeeeQaZmZk4dOgQ/vnPf3r3v+SSS/D6669j79692L17NxYuXAi5XH7WcvXv3x8ZGRnYuXMnMjMzcffdd6O4uNi7XqVS4bHHHsOjjz6KDz/8EFlZWfj111+xYsUKn+Pceeed+Mc//gGn04mrr776XL8uIiIi6iUYPv1EIpHg008/xZ49ezB06FA89NBD+Ne//uVdr1AosHHjRkRGRmLWrFkYNmwY/vGPf0AqlQIApkyZgs8//xzffvstRo4ciUsuucSnR/rLL7+MhIQEXHTRRZg7dy4efvhhaDRnvy3gqaeewujRozFjxgxMmTLFG4Abb/O3v/0NTz/9NAYNGoQbbrgBpaWlPtvcdNNNkMlkmDt3LlQq1Tl8U0RERNSb9L57PnuQSy+9FEeOHPFZ1vA+zaSkJHzxxRct7n/NNdc06aleJzY2Fhs2bPBZVl1d7Z3u06dPk3tCASA0NLTJ+KCNSSQSPPnkk3jyySdb3KaqqgoWiwULFiw447GIiIjo/MLwSR3KbrejqKgIjz/+OMaPH4/Ro0f7u0hERETUjfCyO3WoHTt2ICkpCXv27MFbb73l7+IQERFRN8OWT+pQU6ZMafZyPhERERHAlk8iIiIi6kIMn0RERETUZRg+iYiIiKjLMHwSERERUZdh+CQiIiKiLsPwSURERERdhuGzB+vTpw+WLVvWqm0FQTjrk4uIiIiIOhvDJxERERF1GYZPIiIiIuoyDJ9+8vbbbyMuLg4ul8tn+ZVXXol58+YhKysLV111FaKioqDT6TBmzBj8+OOPHXb+Q4cO4ZJLLoFarUZYWBjuuusuGAwG7/rNmzdj7Nix0Gq1CA4OxgUXXICcnBwAwIEDB3DxxRcjICAAgYGBSEtLw+7duzusbERERNR79brwKYoiTHbTOb/MDnOb92nLYyWvu+46lJeX4+eff/Yuq6qqwoYNG3DzzTfDYDBg1qxZ+PHHH7Fv3z7MmDEDs2fPRm5u7jl/RyaTCZdddhlCQkKwa9cufP755/jxxx9x3333AQAcDgf+9Kc/YfLkyTh48CB++eUX3HXXXRAEAQBw8803Iz4+Hrt27cKePXvw+OOPQy6Xn3O5iIiIqPfrdc92NzvMGLdmnF/O/dvc36CRa1q1bWhoKC677DKsWbMGU6dOBQB8/vnnCA0NxdSpUyGVSjFixAjv9s8//zy++uorfPvtt96Q2F6rV6+G2WzGhx9+CK1WCwB4/fXXMXv2bLz00kuQy+WoqanBFVdcgX79+gEABg0a5N0/NzcXjzzyCAYOHAgASElJOafyEBER0fmj17V89iQ333wz1q5dC6vVCsAdCm+88UZIpVIYjUY8+uijGDx4MIKDg6HT6XD06NEOafnMzMzEiBEjvMETAC644AK4XC4cO3YMoaGhmD9/vre19dVXX0VRUZF320WLFuHOO+/EpZdein/84x/Iyso65zIRERHR+aHXtXyqZWr8Nve3czqGy+WCXq9HQEAAJJLW53O1TN2m88yePRsulwvr1q3DmDFjsG3bNrzyyisAgEceeQQbNmzAv//9b/Tv3x9qtRrXXnstbDZbm87RHFEUvZfQG6tbvmrVKjzwwAP44Ycf8Nlnn+H//u//kJGRgfHjx2PJkiWYO3cu1q1bh++//x7PPPMMPv30U1x99dXnXDYiIiLq3Xpd+BQEodWXvlvicrngkDmgkWvaFD7bSq1W45prrsHq1atx8uRJpKamIi0tDQCwbds2zJ8/3xvoDAYDsrOzO+S8gwcPxgcffACj0eht/dyxYwckEglSU1O9240aNQqjRo3C4sWLMWHCBKxZswbjx48HAKSmpiI1NRUPPfQQbrrpJqxatYrhk4iIiM6Kl9397Oabb8a6deuwcuVK3HLLLd7l/fv3x5dffon9+/fjwIEDmDt3bpOe8edyTpVKhXnz5uGPP/7Azz//jPvvvx+33noroqKicPr0aSxevBi//PILcnJysHHjRhw/fhyDBg2C2WzGfffdh82bNyMnJwc7duzArl27fO4JJSIiImpJr2v57GkuueQShIaG4tixY5g7d653+X/+8x/ccccdmDhxIsLDw/HYY4+htra2Q86p0WiwYcMG/PWvf8WYMWOg0WgwZ84c7yV/jUaDo0eP4oMPPkBFRQViYmJw33334e6774bD4UBFRQVuu+02lJSUIDw8HNdccw2effbZDikbERER9W4Mn34mlUpRWFjYZHmfPn2wadMmn2X33nuvz3xbLsM3HgZq2LBhTY5fJyoqCl999VWz6xQKBT755JNWn5eIiIioIV52JyIiIqIuw/DZC6xevRo6na7Z15AhQ/xdPCIiIiIvXnbvBa688kqMG9f8wPp88hARERF1JwyfvUBAQAACAgL8XQwiIiKis+JldyIiIiLqMgyfRERERNRlGD6JiIiIqMswfBIRERFRl2H4JCIiIqIuw/DZg/Xp0wfLli3zdzGIiIiIWo3hk4iIiIi6DMMn+YXT6YTL5fJ3MYiIiKiLMXz6ydtvv424uLgmAezKK6/EvHnzkJWVhauuugpRUVHQ6XQYM2YMfvzxx3af75VXXsGwYcOg1WqRkJCAe+65BwaDwWebHTt2YPLkydBoNAgJCcGMGTNQVVUFAHC5XHjppZfQv39/KJVKJCYm4oUXXgAAbN68GYIgoLq62nus/fv3QxAEZGdnAwDef/99BAcH47vvvsPgwYOhVCqRk5ODXbt2Ydq0aQgPD0dQUBAmT56MvXv3+pSruroad911F6KioqBSqTB06FB89913MBqNCAwMxBdffOGz/f/+9z9otVro9fp2f19ERETUOXpd+BRFES6T6dxfZnOb9xFFsdXlvO6661BeXo6ff/7Zu6yqqgobNmzAzTffDIPBgFmzZuHHH3/Evn37MGPGDMyePRu5ubnt+l4kEglee+01/PHHH/jggw+wadMmPProo971+/fvx9SpUzFkyBD88ssv2L59O2bPng2n0wkAWLx4MV566SU89dRTOHLkCNasWYOoqKg2lcFkMmHp0qV47733cPjwYURGRkKv12PevHnYtm0bfv31V6SkpGDWrFne4OhyuTBz5kzs3LkTH3/8MY4cOYJ//OMfkEql0Gq1uPHGG7Fq1Sqf86xatQrXXnstn/pERETUDfW6x2uKZjOOjU7rkGOVtHH7AXv3QNBoWrVtaGgoLrvsMqxZswZTp04FAHz++ecIDQ3F1KlTIZVKMWLECO/2zz//PL766it8++23uO+++9pYMuDBBx/0TicnJ+Pvf/87/vKXv2D58uUAgH/+859IT0/3zgPAkCFDAAB6vR6vvvoqXn/9dcybNw8A0K9fP1x44YVtKoPdbsfy5ct9Ptcll1zis83bb7+NkJAQbNmyBRdddBF+/PFH/P7778jMzERqaioAoG/fvt7t77zzTkycOBGFhYWIjY1FeXk5vvvuO2RkZLSpbERERNQ1el3LZ09y8803Y+3atbBarQCA1atX48Ybb4RUKoXRaMSjjz6KwYMHIzg4GDqdDkePHm13y+fPP/+MadOmIS4uDgEBAbjttttQUVEBo9EIoL7lszmZmZmwWq0trm8thUKB4cOH+ywrLS3FwoULkZqaiqCgIAQFBcFgMCAvLw8AcODAAcTHx3uDZ2Njx47FkCFD8OGHHwIAPvroIyQmJuKiiy46p7ISERFR5+h1LZ+CWo0Be/ec0zFcLhdq9XoEBgRAIml9PhfU6jadZ/bs2XC5XFi3bh3GjBmDbdu24ZVXXgEAPPLII9iwYQP+/e9/o3///lCr1bj22mths9nadA4AyMnJwaxZs7Bw4UL8/e9/R2hoKLZv344FCxbAbrcDANRnKPuZ1gHwfkcNbzuoO27j4wiC4LNs/vz5KCsrw7Jly5CUlASlUokJEyZ4P+fZzg24Wz9ff/11PP7441i1ahVuv/32JuchIiKi7qHXtXwKggCJRnPuL7W6zfu0NfCo1Wpcc801WL16NT755BOkpqYiLc19y8C2bdswf/58XH311Rg2bBiio6O9nXfaavfu3XA4HHj55Zcxfvx4pKamorCw0Geb4cOH46effmp2/5SUFKjV6hbXR0REAACKioq8y/bv39+qsm3btg0PPPAAZs2ahSFDhkCpVKK8vNy7ftiwYcjPz8fx48dbPMYtt9yC3NxcvPbaazh8+LD31gAiIiLqfnpd+Oxpbr75Zqxbtw4rV67ELbfc4l3ev39/fPnll9i/fz8OHDiAuXPntntoon79+sHhcOD//b//h1OnTuGjjz7CW2+95bPN4sWLsWvXLtxzzz04ePAgjh49ijfffBPl5eVQqVR47LHH8Oijj+LDDz9EVlYWfv31V6xYscJb1oSEBCxZsgTHjx/HunXr8PLLL7eqbP3798dHH32EzMxM/Pbbb7j55pt9WjsnT56Miy66CHPmzEFGRgZOnz6N77//Hj/88IN3m5CQEFxzzTV45JFHMH36dMTHx7freyIiIqLOx/DpZ5dccglCQ0Nx7NgxzJ0717v8P//5D0JCQjBx4kTMnj0bM2bMwOjRo9t1jpEjR+KVV17BSy+9hKFDh2L16tVYunSpzzapqanYuHEjDhw4gLFjx2LChAn45ptvIJO578x46qmn8Le//Q1PP/00Bg0ahBtuuAGlpaUAALlcjk8++QRHjx7FiBEj8NJLL+H5559vVdlWrlyJqqoqjBo1CrfeeiseeOABREZG+myzdu1ajBkzBjfddBMGDx6MRx991NsLv86CBQtgs9lwxx13tOs7IiIioq4hiG0ZH8hPamtrERQUhJqaGgQGBvqss1gsOH36NJKTk6FSqTrkfC6XC7W1tQgMDGzTPZ/UcdpaB6tXr8Zf//pXFBYWQqFQtLhdZ/x56a3sdjvWr1+PWbNmQS6X+7s45y3Wg/+xDvyPdeB/ramDM+W1hnpdhyM6v5hMJpw+fRpLly7F3XfffcbgSURERP7HZr1eYPXq1dDpdM2+6sbq7K3++c9/YuTIkYiKisLixYv9XRwiIiI6C7Z89gJXXnklxo0b1+y63n55YsmSJViyZIm/i0FEREStxPDZCwQEBPBRkkRERNQj8LI7EREREXWZXhM+2zsGJp1fesDgDkRERL1aj7/srlAoIJFIUFhYiIiICCgUinN+tKLL5YLNZoPFYuFQS37SGXUgiiLKysogCEKvvxeWiIiou+rx4VMikSA5ORlFRUVNHhnZXqIowmw2N/sscuoanVUHgiAgPj4eUqm0w45JRERErdfjwyfgbv1MTEyEw+Fo8uSb9rDb7di6dSsuuugitpD5SWfVgVwuZ/AkIiLyo14RPgF4L6V2RFCRSqVwOBxQqVQMn37COiAiIuqd2nUz3fLly72PJ0xLS8O2bdvOuP2WLVuQlpYGlUqFvn374q233mpXYYmIiIioZ2tz+Pzss8/w4IMP4sknn8S+ffswadIkzJw5E7m5uc1uf/r0acyaNQuTJk3Cvn378MQTT+CBBx7A2rVrz7nwRERERNSztDl8vvLKK1iwYAHuvPNODBo0CMuWLUNCQgLefPPNZrd/6623kJiYiGXLlmHQoEG48847cccdd+Df//73OReeiIiIiHqWNt3zabPZsGfPHjz++OM+y6dPn46dO3c2u88vv/yC6dOn+yybMWMGVqxYAbvd3uz9fFarFVar1TtfU1MDAKisrITdbm9LkdvFbrfDZDKhoqKC9xv6CevA/1gH3QPrwf9YB/7HOvC/1tSBXq8HcPYxtdsUPsvLy+F0OhEVFeWzPCoqCsXFxc3uU1xc3Oz2DocD5eXliImJabLP0qVL8eyzzzZZnpyc3JbiEhEREVEX0+v1CAoKanF9u3q7Nx53URTFM47F2Nz2zS2vs3jxYixatMg773K5UFlZibCwsC4Zd7O2thYJCQnIy8tDYGBgp5+PmmId+B/roHtgPfgf68D/WAf+15o6EEURer0esbGxZzxWm8JneHg4pFJpk1bO0tLSJq2bdaKjo5vdXiaTISwsrNl9lEollEqlz7Lg4OC2FLVDBAYG8g+5n7EO/I910D2wHvyPdeB/rAP/O1sdnKnFs06bOhwpFAqkpaUhIyPDZ3lGRgYmTpzY7D4TJkxosv3GjRuRnp7O+zaIiIiIzjNt7u2+aNEivPfee1i5ciUyMzPx0EMPITc3FwsXLgTgvmR+2223ebdfuHAhcnJysGjRImRmZmLlypVYsWIFHn744Y77FERERETUI7T5ns8bbrgBFRUVeO6551BUVIShQ4di/fr1SEpKAgAUFRX5jPmZnJyM9evX46GHHsIbb7yB2NhYvPbaa5gzZ07HfYoOplQq8cwzzzS59E9dh3Xgf6yD7oH14H+sA/9jHfhfR9aBIJ6tPzwRERERUQdp1+M1iYiIiIjag+GTiIiIiLoMwycRERERdRmGTyIiIiLqMgyfjSxfvhzJyclQqVRIS0vDtm3b/F2k88qSJUsgCILPKzo62t/F6tW2bt2K2bNnIzY2FoIg4Ouvv/ZZL4oilixZgtjYWKjVakyZMgWHDx/2T2F7qbPVwfz585v8LsaPH++fwvZSS5cuxZgxYxAQEIDIyEj86U9/wrFjx3y24W+hc7WmDvhb6Fxvvvkmhg8f7h1IfsKECfj++++96zvqN8Dw2cBnn32GBx98EE8++ST27duHSZMmYebMmT5DR1HnGzJkCIqKiryvQ4cO+btIvZrRaMSIESPw+uuvN7v+n//8J1555RW8/vrr2LVrF6KjozFt2jTo9fouLmnvdbY6AIDLLrvM53exfv36Lixh77dlyxbce++9+PXXX5GRkQGHw4Hp06fDaDR6t+FvoXO1pg4A/hY6U3x8PP7xj39g9+7d2L17Ny655BJcddVV3oDZYb8BkbzGjh0rLly40GfZwIEDxccff9xPJTr/PPPMM+KIESP8XYzzFgDxq6++8s67XC4xOjpa/Mc//uFdZrFYxKCgIPGtt97yQwl7v8Z1IIqiOG/ePPGqq67yS3nOV6WlpSIAccuWLaIo8rfgD43rQBT5W/CHkJAQ8b333uvQ3wBbPj1sNhv27NmD6dOn+yyfPn06du7c6adSnZ9OnDiB2NhYJCcn48Ybb8SpU6f8XaTz1unTp1FcXOzzu1AqlZg8eTJ/F11s8+bNiIyMRGpqKv785z+jtLTU30Xq1WpqagAAoaGhAPhb8IfGdVCHv4Wu4XQ68emnn8JoNGLChAkd+htg+PQoLy+H0+lEVFSUz/KoqCgUFxf7qVTnn3HjxuHDDz/Ehg0b8O6776K4uBgTJ05ERUWFv4t2Xqr7s8/fhX/NnDkTq1evxqZNm/Dyyy9j165duOSSS2C1Wv1dtF5JFEUsWrQIF154IYYOHQqAv4Wu1lwdAPwtdIVDhw5Bp9NBqVRi4cKF+OqrrzB48OAO/Q20+fGavZ0gCD7zoig2WUadZ+bMmd7pYcOGYcKECejXrx8++OADLFq0yI8lO7/xd+FfN9xwg3d66NChSE9PR1JSEtatW4drrrnGjyXrne677z4cPHgQ27dvb7KOv4Wu0VId8LfQ+QYMGID9+/ejuroaa9euxbx587Blyxbv+o74DbDl0yM8PBxSqbRJei8tLW2S8qnraLVaDBs2DCdOnPB3Uc5LdSMN8HfRvcTExCApKYm/i05w//3349tvv8XPP/+M+Ph473L+FrpOS3XQHP4WOp5CoUD//v2Rnp6OpUuXYsSIEXj11Vc79DfA8OmhUCiQlpaGjIwMn+UZGRmYOHGin0pFVqsVmZmZiImJ8XdRzkvJycmIjo72+V3YbDZs2bKFvws/qqioQF5eHn8XHUgURdx333348ssvsWnTJiQnJ/us52+h852tDprD30LnE0URVqu1Q38DvOzewKJFi3DrrbciPT0dEyZMwDvvvIPc3FwsXLjQ30U7bzz88MOYPXs2EhMTUVpaiueffx61tbWYN2+ev4vWaxkMBpw8edI7f/r0aezfvx+hoaFITEzEgw8+iBdffBEpKSlISUnBiy++CI1Gg7lz5/qx1L3LmeogNDQUS5YswZw5cxATE4Ps7Gw88cQTCA8Px9VXX+3HUvcu9957L9asWYNvvvkGAQEB3tadoKAgqNVqCILA30InO1sdGAwG/hY62RNPPIGZM2ciISEBer0en376KTZv3owffvihY38DHdQTv9d44403xKSkJFGhUIijR4/2GeKBOt8NN9wgxsTEiHK5XIyNjRWvueYa8fDhw/4uVq/2888/iwCavObNmyeKonuImWeeeUaMjo4WlUqleNFFF4mHDh3yb6F7mTPVgclkEqdPny5GRESIcrlcTExMFOfNmyfm5ub6u9i9SnPfPwBx1apV3m34W+hcZ6sD/hY63x133OHNQBEREeLUqVPFjRs3etd31G9AEEVRPNekTERERETUGrznk4iIiIi6DMMnEREREXUZhk8iIiIi6jIMn0RERETUZRg+iYiIiKjLMHwSERERUZdh+CQiIiKiLsPwSURERERdhuGTiIiIiLoMwycRERERdRmGTyIiIiLqMgyfRERERNRl/j+cj0rHP7vo3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # vertikale Bereich auf (0,1) setzten\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 729us/step - loss: 0.3231 - accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32310956716537476, 0.8840000033378601]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagen Treffen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming model is your trained Keras model\n",
    "y_pred_probabilities = model.predict(X_new)\n",
    "y_pred_classes = np.argmax(y_pred_probabilities, axis=-1)\n",
    "np.array(class_names)[y_pred_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Das Gradientenverfahren***\n",
    "\n",
    "- Allgemeiner Algoritmus zur Optimierung, der optimale Lösungen für eine Vielzahl von Fragestellungen ermitteln kann.\n",
    "Der Grundgedanke beim Gradientenverfahren ist, die Parameter iterativ so zu verändern das eine Kostenfunktion minimiert wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Grundlegende ideen bei einem Neural Network***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Deep Neural Network (DNN) ist eine leistungsstarke Technik des maschinellen Lernens, die in verschiedenen Bereichen Anwendung findet. Die Bedeutung eines Deep Neural Networks liegt in seiner Fähigkeit, komplexe Muster in Daten zu erkennen und Vorhersagen oder Klassifikationen basierend auf diesen Mustern zu treffen.\n",
    "\n",
    "\n",
    " Hier sind einige der Schlüsselaspekte, die die Bedeutung von DNNs verdeutlichen:\n",
    "\n",
    "\n",
    "- 1. Mustererkennung: DNNs sind in der Lage, Muster in großen und komplexen Datensätzen zu erkennen (die nicht Linear sind), die von Menschen schwer oder unmöglich zu identifizieren sind. Dies macht sie besonders wertvoll in Anwendungen wie Bilderkennung, Spracherkennung und Natural Language Processing (NLP).\n",
    "\n",
    "\n",
    "- 2. Klassifikation und Vorhersage: DNNs ermöglichen die Klassifikation von Daten in verschiedene Kategorien oder die Vorhersage zukünftiger Ereignisse. Dies wird in Anwendungen wie Spam-Erkennung, Gesichtserkennung, medizinischer Diagnose und Finanzprognosen genutzt.\n",
    "\n",
    "\n",
    "- 3. Skalierbarkeit: DNNs können große Mengen an Daten verarbeiten und sind in der Lage, Modelle mit Tausenden oder Millionen von Parametern zu trainieren. Dies ermöglicht die Bewältigung komplexer Aufgaben und die Verarbeitung großer Datensätze.\n",
    "\n",
    "\n",
    "- 4. Automatisierung: DNNs können automatisch und kontinuierlich lernen, was bedeutet, dass sie sich an neue Daten und Veränderungen in der Umgebung anpassen können, ohne dass eine manuelle Anpassung erforderlich ist.\n",
    "\n",
    "\n",
    "- 5. Vielseitigkeit: DNNs finden in verschiedenen Bereichen Anwendung, darunter Bildverarbeitung, Sprachverarbeitung, autonome Fahrzeuge, medizinische Diagnostik, Empfehlungssysteme und vieles mehr. Sie sind eine Kernkomponente von Künstlicher Intelligenz (KI) und Deep Learning.\n",
    "\n",
    "\n",
    "- 6. Forschung und Innovation: DNNs haben zu bedeutenden Fortschritten in der KI-Forschung geführt und neue Möglichkeiten für innovative Anwendungen eröffnet. Sie sind ein Motor für die Entwicklung neuer Technologien und Lösungen.\n",
    "\n",
    "\n",
    "Die Bedeutung eines Deep Neural Networks liegt in seiner Fähigkeit, komplexe Aufgaben zu bewältigen und menschenähnliche Leistungen bei der Verarbeitung von Informationen zu erzielen. Dies hat Auswirkungen auf viele Branchen und trägt zur Transformation von Geschäftsmodellen und zur Lösung komplexer Herausforderungen bei."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Blackbox***: \n",
    "\n",
    "- Als Blockbox wir in Data Science die Hiddenlayers gemeint die der Programmier nicht sehen. Da nicht nachvollziebar ist wie das Model den Output generiert. Das Auch Deepl Learning Neurale Netzwerke Hidden Layers nutzen und die für den Programmierer auch eine Blackbox ist (siehe bild)\n",
    "\n",
    "![Hidden Layer](/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/hiddenlayer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Arten von rekurrenten neuronalen Netzwerken (RNNs)***\n",
    "\n",
    "Eine Eingabesequenz ist einer Ausgabe zugeordnet. Sie können sie jedoch flexibel an verschiedene Konfigurationen für bestimmte Zwecke anpassen. Im Folgenden sind einige gänige RNN-Typen aufgeführt.\n",
    "\n",
    "#### **Eins-zu-viele**\n",
    "- Dieser RNN-Typ kanalisiert einen Eingang an mehrere Ausgänge. Es ermöglicht sprachliche Anwendungen wie Bildunterschirften, indem ein Satz aus einem einzigen Schüsselwort generiert wird.\n",
    "\n",
    "#### **Viel-zu-viele**\n",
    "- Das Modell verwendet mehrere Eingaben, um mehrere Ausgaben vorherzusagen. Sie können beispielsweise einen Sprachübersetzter mit einem RNN erstellen, der einen Satz analysiert und die Wörter in einer anderen Sprache korrekt strukturiert.\n",
    "\n",
    "#### **Viel-zu-eins**\n",
    "- Mehrere Eingänge werden einem Ausgang zugeordet. Dies ist hilfreich bei Anwendungen wie der Stimmungsanalyse, bei der das Modell positive, negative und neutrale Stimmungen der Kunden anhand von Kundenreferenzen vorhersagt.\n",
    "\n",
    "\n",
    "<img src=\"/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/rnn_models.jpeg\" width=\"500\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rekurrentes neuronales Netzwerk im Vergleich zu neuronalem Feed-Forward-Netzwerk**\n",
    "\n",
    "- Wie Rnns sind neuronale Feed-Forward-Netze künstliche neuronale Netze, die Informationen von einem Ende zum Ende der Architektur weiterleiten. \n",
    "Ein neuronales Feed-Forward-Netzwerk kann einfache Klassifizierungens-, Regressions- oder Erkennungsaufgaben ausführen, aber es kann sich nicht an die vorherige Eingabe erinnern, die es verarbeitet hat.\n",
    "\n",
    "- Zumbeispiel vergisst es \"Apfel\", wenn sein Neuron das Wort *ist* verarbeitet.\n",
    "Das RNN überwindet diese Speicherbeschränkung, indem es einen verborgenen Gedächtniszustand in das Neuron einbezieht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Backpropagation***\n",
    "\n",
    "\n",
    "Was macht Backpropagation ?\n",
    "- Bei jedem Trainingsdatenpunkt trifft der Backpropagation-Algorithmus zuerst eine Vohersage (im Vorwärtsdurchlauf), bestimmt den Fehler, durchläuft dann rückwärst jede Sicht, um den Fehlerbeitrag jeder Verbindung zuermitteln (im Rückwärtsdurchlauf), und verändert schließlich die Gewichte der Verbindungen, um den Fehler zu verringern (als Schritt im Gradientenverfahren)\n",
    "    - Es ist wichtig, alle Verbindungsgewichte der verborgenen Sichten mit Zufallswerte zu initialisieren, denn sonst wird das Training fehlschlagen. Initialisieren Sie zum Beispiel alle Gewichte und Bias mit null, werden alle Neuronen in einer Schicht identisch sein, und die Backpropagation wird sie exakt gleich behandeln, womit sie identisch bleiben.      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Weights and Bias***\n",
    "- In einem einfachen neuronalen Netzwerk wird die Berechnung ähnlich wie bei einer linearen Regression durchgeführt, bei der eine Ausgabe \n",
    "**y** anhand einer linearen Kombination der Eingaben **x**, eines Intercepts (Gewichts) und eines Slopes (Bias) berechnet wird. Der wesentliche Unterschied besteht darin, dass ein neuronales Netzwerk aus mehreren Schichten von Neuronen besteht, die miteinander verbunden sind und nichtlinear miteinander interagieren. Diese **nichtlineare Interaktion** wird durch die Verwendung einer **Aktivierungsfunktion** in jedem Neuron ermöglicht. Dadurch ist das neuronale Netzwerk in der Lage, **komplexere Beziehungen** zwischen den Eingaben und der Ausgabe zu erfassen und zu modellieren.\n",
    "\n",
    "\n",
    "<img src=\"/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/Terminologie_weights.png\" width=\"400\" />\n",
    "\n",
    "<img src=\"/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/Terminologie_baises.png\" width=\"400\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation Function apply a nonlinear transformation and decide whether a neuron should be activated or not**\n",
    "\n",
    "\n",
    "- Ohne eine Aktivierungsfunktion ist es eine stacked Lineare Funktion zulösen. *Die Aktiverungsfunktion unbetten die funktion des Rnns*\n",
    "- wenn wir jedoch ein nicht Lineares Problem haben, brauchen wir eine nicht Lineare aktiverungs funktion\n",
    "\n",
    "Es gibt viele aktivierungsfunktionen für ein Neurales Network\n",
    "- Step Function\n",
    "- TanH\n",
    "- Leaky ReLU\n",
    "- Softmax\n",
    "- ReLU (Rectified Linear Unit)\n",
    "- Softplus\n",
    "- Sigmoid \n",
    "- Die Funktion **ReLU** ist eine Aktivierungs-funktion, die in neuronalen Netzten verwendet wird. Sie steht für **(Rectified Linear Unit)**. \n",
    "Diese Funktion gibt einfach den Eingabewert zurück, **wenn er positiv ist, und gibt 0 zurück, wenn er negativ ist**. Es ist eine weit verbreitete Aktivierungsfunktion aufgrund ihrer Einfachheit und ihrer guten Leistung in vielen Anwendungen.\n",
    "\n",
    "![Arten von Aktiverierungsfunktion](/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/aktivierungsfunktionen.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formel :\n",
    "\n",
    "\n",
    "![Beschreibung des Bildes](/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/eq_29.png)\n",
    "\n",
    "\n",
    "\n",
    "- y(t) = Steht für die Ausgabe des neuronalen Netzes zur Zeit (t). \n",
    "Es repräsentiert das, was das Netzwerk zu einem bestimmten Zeitpunkt vorhersagt oder generiert.\n",
    "\n",
    "\n",
    "- **Wx** und **Wy** sind Gewichtsmatrizen, die die Verbindungen zwischen den Eigaben **Xt** und den vorherigen Ausgaben **yt−1** und den versteckten Schichten des neuronalen Netzes steuern. WXT und WTY bezeichne die Transponierten dieser Gewichtsmatrizen.\n",
    "\n",
    "- **Xt** ist die Eingabe des neuronales Netzes zum Zeitpunkt **t**. Sie repräsentiert die Daten oder Informationen, die dem Netzwerk zu diesem Zeitpunkt präsentiert werden.\n",
    "\n",
    "- **yt-1** ist die Ausgabe des neuronalen Netzes zum vorherigen Zeitpunkt t - 1. Sie wird verwendet, um die Informationen aus vergangenen Zustände zu berücksichtigen.\n",
    "\n",
    "- **b** ist der Bias-Vektor für die versteckten Schichten des neuronalen Netzes, ER ermöglicht es dem Netzwerk, Verschiebungen in den Daten zu berücksichtigen.\n",
    "\n",
    "Insgesamt wird die Ausgabe des neuronalen Netzes zum Zeitpunkt **t**\n",
    "als gewichtete Summe der Eingaben **Xt** und der vorherigen Ausgabe **yt-1** berechnet, die dann durch **die ReLU-Aktivierungsfunktion** gehen. Dieser Prozess wird verwendet, um Vorhersagen zu machen oder Daten zu generieren, basierend auf den Informationen zu diesem Zeitpunkt und vergangenen Zuständen des Netzwerks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel 15\n",
    "\n",
    "## 1. Verarbeiten von Sequenzen mit Rnns und Cnns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN = Rekurrente neuronale Netze\n",
    "CNN = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgendes wird im Kaptiel Thematisert\n",
    "1. Grundlegende Konzepte auf den RNN aufbaut und werden erfahren wie man sie per Backpropagation durch die Zeit trainiert\n",
    "2. Schwierigkeiten der Modelle Thematisieren\n",
    "    - Instablie Gradienten die durch verschiedene Techniken abgemildert werden können - unter anderem Recurrent Dropout und Recurrent Layer Normalization\n",
    "    - Ein sehr begrenztes Kurzeitgedächtnis das mithilfe von LSTM und GRU-Zellen erweiter werden kann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Rnn sind nicht die einzigen Neuronal Netz die sequenzielle Daten verarbeiten können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2,offsets1, offsets2 = np.random.rand(4,batch_size, 1)\n",
    "    time = np.linspace(0,1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))    # Welle 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))   # Welle 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)     # + Rauschen\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 51, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = 50\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellungs eines Traininigs einen Validierungs und einen Testdatensattz\n",
    "n_steps = 50\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000: -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wir haben also 10000 Reihen mit 50 Spalten (10000, 51, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Wir haben also 10000 Reihen mit 50 Spalten\", series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der X Test Datensatz besthet aus:  (7000, 50, 1) Der Y Test Datensatz besthet aus:  (7000, 1)\n",
      "Der X Validierungs Datensatz besthet aus:  (2000, 50, 1) Der Validierungs Datensatz besthet aus:  (2000, 1)\n",
      "Der X_test Datensatz besthet aus:  (1000, 50, 1) Der y_test Datensatz besteht  aus:  (999, 51, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Der X Test Datensatz besthet aus: \", X_train.shape, \"Der Y Test Datensatz besthet aus: \", y_train.shape)\n",
    "print(\"Der X Validierungs Datensatz besthet aus: \", X_valid.shape,\"Der Validierungs Datensatz besthet aus: \", y_valid.shape)\n",
    "print(\"Der X_test Datensatz besthet aus: \", X_test.shape,\"Der y_test Datensatz besteht  aus: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Daten typ** <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shape der Daten (7000, 50, 1) (7000, 1) (2000, 50, 1) (2000, 1) (1000, 50, 1) (999, 51, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"**Daten typ**\", type(X_train), type(y_train), type(X_valid), type(y_valid), type(X_test), type(y_test))\n",
    "# alle sind numpy arrays und haben die gleiche Anzahl an Dimensionen\n",
    "print(\"Shape der Daten\",X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020177832"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:,-1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Mean squared Error MSE***\n",
    "Der mittlere quadratische Fehler (MSE) ist eine gängige Metrik zur Bewertung der Leistung von Regressionsmodellen. Sie misst die durchschnittliche quadratische Abweichung zwischen den tatsächlichen und den vorhergesagten Werten.\n",
    "\n",
    "Hier ist eine schrittweise Erklärung des MSE:\n",
    "1. Differenz zwischen tatsächlichem und vorhergesagtem Wert: Für jede Instanz in den Daten wird die Differenz zwischen dem tatsächlichen Wert \n",
    "​und dem vorhergesagten Wert berechnet.\n",
    "\n",
    "2. Quadrat der Differenz: Die Differenzen werden quadriert. Dies stellt sicher, dass negative und positive Abweichungen gleich behandelt werden und dass größere Abweichungen stärker ins Gewicht fallen.\n",
    "\n",
    "3. Durchschnitt der quadrierten Differenzen: Die quadrierten Differenzen werden dann gemittelt, um den MSE zu erhalten. Dies geschieht, indem man die Summe der quadrierten Differenzen durch die Anzahl der Instanzen teilt.\n",
    "\n",
    "**Mathematisch ausgedrückt:**\n",
    "\n",
    "\n",
    "<img src=\"/Users/riccardo/Desktop/Repositorys_Github/Training/Scripts/Models/pictures_expl/mse.png\" width=\"400\" />\n",
    "\n",
    "\n",
    "\n",
    "wo: \n",
    "n die anzahl \n",
    "yi der tatsächliche Wert den i-ten Instanz ist\n",
    "y^i der vorherergesagte Wert der i-ten Instanz ist.\n",
    "\n",
    "\n",
    "**WICHTIG:**\n",
    "- Ein niedriger MSE-Wert deutet drauf hin, dass das Modell gute Vorhersagen macht, da die tatsächlichen und vorhergesagten Werte eng beieinander liegen. \n",
    "\n",
    "- Ein hoher MSE-Wert deutet hingegen darauf hin, dass das Model schlechte Vorhersagen macht, da die Abweichung zwischen den tatäschlich und den vorhergesagten Werten groß ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Flatten-Schicht: ist also wenn ich mir das Modul vorstellen das Input des Models\n",
    "Vorschläge anzeigen\n",
    "\n",
    "Die Flatten-Schicht kann als \"Eingangstrichter\" des Modells betrachtet werden. Sie nimmt die Eingabedaten entgegen und formatiert sie so, dass sie von den folgenden Schichten des Modells verarbeitet werden können.\n",
    "\n",
    "**Details:**\n",
    "\n",
    "Die Flatten-Schicht nimmt Daten mit einer beliebigen Form entgegen und \"ebnet\" sie in einen eindimensionalen Vektor.\n",
    "Dies ist notwendig, da die meisten anderen Schichten des Modells mit Daten in Form von Vektoren arbeiten.\n",
    "Die Größe des Vektors hängt von der Anzahl der Merkmale in den Eingabedaten ab.\n",
    "Beispiel:\n",
    "\n",
    "Angenommen, Sie haben Eingabedaten mit der Form (50, 10). Dies bedeutet, dass Sie 50 Datensätze mit jeweils 10 Merkmalen haben.\n",
    "\n",
    "Die Flatten-Schicht würde diese Daten in einen Vektor mit 500 Elementen umwandeln.\n",
    "Jedes Element des Vektors würde einem Merkmal aus einem der 50 Datensätze entsprechen.\n",
    "Vorsichtsmaßnahmen:\n",
    "\n",
    "Die Flatten-Schicht kann nur für Daten verwendet werden, die bereits in Form eines Arrays vorliegen.\n",
    "Wenn Ihre Daten in einem anderen Format vorliegen, müssen Sie sie vor der Verwendung der Flatten-Schicht in ein Array konvertieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erklärung des Code abschnitt:**\n",
    "\n",
    "- **keras.Models.Sequential** leitet ein model ein\n",
    "- **keras.layer.Flatten** ist das Input, wenn man sich das Model vorsellt.\n",
    "- **keras.layer.Dense** ist das Output des Models. \n",
    "\n",
    "    - In unseren konrekten code ist noch keine Hidden layer eingebaut\n",
    "Somit können wir sehen das wir nur ein Input sowie Output haben des RNN Models. Jedoch noch keine Hiddenlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50,1], name = \"Input\"),\n",
    "    keras.layers.Dense(1, name = \"Output\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In diesem Fall wird **mean_squared_error** verwendet, was den mittleren quadratischen Fehler berechnet. Diese Funktion eignet sich gut für Regressionsaufgaben, bei denen kontinuierliche Werte vorhergesagt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/219 [..............................] - ETA: 29s - loss: 0.3415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 13:44:20.131765: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 319us/step - loss: 0.0563\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 287us/step - loss: 0.0138\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 280us/step - loss: 0.0109\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 283us/step - loss: 0.0095\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 281us/step - loss: 0.0083\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 285us/step - loss: 0.0073\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 277us/step - loss: 0.0065\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 276us/step - loss: 0.0059\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 280us/step - loss: 0.0054\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 279us/step - loss: 0.0051\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 279us/step - loss: 0.0048\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 277us/step - loss: 0.0045\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 280us/step - loss: 0.0044\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 278us/step - loss: 0.0043\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 278us/step - loss: 0.0041\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 278us/step - loss: 0.0040\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 279us/step - loss: 0.0039\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 282us/step - loss: 0.0038\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 277us/step - loss: 0.0037\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 280us/step - loss: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1692c8a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (Flatten)             (None, 50)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51\n",
      "Trainable params: 51\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss: ist ein Maß dafür wie gut oder schlecht Ihr Modell während des Trainings abschneidet. \n",
    "\n",
    "**model.compile(loss='mean_squared_error', optimizer='adam')** auch (MSE) genannt.\n",
    "In meinem Fall habe ich als *loss funktion* den **'mean_squared_error'** eingesetzt.\n",
    "\n",
    "- Höhe des Verlustes: Ein niedriger Verlustwert bedeutet, dass Ihr Modell gute Vorhersagen macht und die tatsächlichen Werte gut reproduziert. Ein hoher Verlustwert deutet darauf hin, dass Ihr Modell schlechte Vorhersagen macht und die tatsächlichen Werte nicht gut reproduziert.\n",
    "\n",
    "- Veränderung des Verlustes über die Epochen: Wenn der Verlust im Laufe des Trainings abnimmt, deutet dies darauf hin, dass Ihr Modell besser wird und die Vorhersagen genauer werden. Wenn der Verlust jedoch stagniert oder steigt, kann dies darauf hinweisen, dass Ihr Modell nicht mehr lernt oder überangepasst ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein einfaches RNN implementieren\n",
    "### SimpleRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape = [None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8869 - accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6785 - accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.4534 - accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.3686 - accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.3112 - accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.2036 - accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.1416 - accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1401 - accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1400 - accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1409 - accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1697acfa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Rnns\n",
    "hier ist es ein Deep Rnn da wir ein hidden layers nutzen. Jedoch erstmal eine Linear Funktion da wir noch keine Aktivierungsfunktion haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0151\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0039\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0036\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0033\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0032\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0032\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0031\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0030\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0030\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0030\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0029\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0029\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0028\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0028\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0028\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0027\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0027\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0027\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0027\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1697966a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 0.0302\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0043\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0036\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0036\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0036\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0033\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0033\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0032\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0033\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0031\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0031\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0030\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0030\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0029\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0030\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0029\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0028\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0028\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0029\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b845100>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (None, None, 20)          440       \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 20)                820       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:] # X_new ist die Zeitreihe bis 50 und Y_new ist die Zeitreihe ab 50\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]\n",
    "# Berechnung des MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017976176"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.losses.mean_squared_error(Y_new, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seite 513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]  # 10 Schritte in die Zukunft\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 60, 1),\n",
       " (7000, 50, 1),\n",
       " (7000, 10),\n",
       " (2000, 50, 1),\n",
       " (2000, 10),\n",
       " (1000, 50, 1),\n",
       " (1000, 10))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape, X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([ \n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 0.1545\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.1449\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1444\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1442\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1444\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.1442\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.1442\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1442\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1442\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1440\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1440\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.1441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c9df970>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39600024"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:,-1]\n",
    "np.mean(keras.losses.mean_squared_error(Y_valid, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seite 514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((10000, n_steps, 10)) # jedes Ziel ist eine Sequenz von 10-D-Vektoren\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:,:, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]  \n",
    "Y_train = Y[:7000]\n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 6ms/step - loss: 0.0686\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0413\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0370\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0345\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0328\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0317\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0311\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0306\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0301\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0298\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0294\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0290\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0286\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0282\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0280\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0277\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0276\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0271\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0270\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176b81d30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "model.compile(loss = 'mean_squared_error',optimizer='adam')\n",
    "model.fit(X_train, Y_train,  epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die TimeDistributed-Schicht ermöglicht es, eine Schicht (wie z.B. eine Dichteschicht) auf jeden Zeitschritt dieser Sequenz anzuwenden. Das bedeutet, dass die Schicht auf jeden einzelnen Datenpunkt in der Sequenz angewendet wird, anstatt die gesamte Sequenz als Ganzes zu betrachten.\n",
    "\n",
    "In Ihrem Code wird die TimeDistributed-Schicht verwendet, um eine Dichteschicht (Dense-Schicht) auf jeden Zeitschritt der Ausgabe einer vorherigen SimpleRNN-Schicht anzuwenden. Dies erlaubt dem Modell, auf jede Zeitstufe der Ausgabe der vorherigen Schicht individuell zu reagieren und Muster in den Daten zu erkennen.\n",
    "\n",
    "Insgesamt ermöglicht die Verwendung der TimeDistributed-Schicht eine feinere Steuerung und Anpassung des Modells an die Daten, insbesondere in Sequenzdatensätzen wie Zeitreihen oder Textdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardo/anaconda3/envs/model/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 6ms/step - loss: 0.0490 - last_time_step_mse: 0.0373\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0354 - last_time_step_mse: 0.0232\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0320 - last_time_step_mse: 0.0201\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0291 - last_time_step_mse: 0.0171\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0271 - last_time_step_mse: 0.0149\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0256 - last_time_step_mse: 0.0130\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0234 - last_time_step_mse: 0.0104\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0221 - last_time_step_mse: 0.0092\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0215 - last_time_step_mse: 0.0090\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0209 - last_time_step_mse: 0.0085\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0204 - last_time_step_mse: 0.0079\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0201 - last_time_step_mse: 0.0077\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0195 - last_time_step_mse: 0.0073\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0194 - last_time_step_mse: 0.0073\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0196 - last_time_step_mse: 0.0077\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0192 - last_time_step_mse: 0.0074\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0190 - last_time_step_mse: 0.0074\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0189 - last_time_step_mse: 0.0074\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0184 - last_time_step_mse: 0.0069\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0182 - last_time_step_mse: 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176d01d60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape = [None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Was sind Gradienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
